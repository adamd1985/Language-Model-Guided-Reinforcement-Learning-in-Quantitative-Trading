{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - Run Trading Strategies By Prompt Version and Risk Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs every prompt configuration created during this research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:39:13.829574Z",
     "iopub.status.busy": "2024-09-23T14:39:13.829218Z",
     "iopub.status.idle": "2024-09-23T14:39:14.190909Z",
     "shell.execute_reply": "2024-09-23T14:39:14.189908Z",
     "shell.execute_reply.started": "2024-09-23T14:39:13.829533Z"
    },
    "papermill": {
     "duration": 0.761376,
     "end_time": "2024-09-17T19:46:45.797391",
     "exception": false,
     "start_time": "2024-09-17T19:46:45.036015",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "if False:\n",
    "    %pip install python-dotenv==1.0.1\n",
    "    %pip install tqdm==4.66.5\n",
    "    %pip install openai==1.58.1\n",
    "\n",
    "%load_ext dotenv\n",
    "\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\", '/fundamentals')\n",
    "LLM_PROMPTS_PATH = os.getenv(\"LLM_PROMPTS_PATH\", '/prompts')\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\", '/fundamentals')\n",
    "HISTORIC_PATH = os.getenv(\"HISTORIC_PATH\", '/historic')\n",
    "MACRO_PATH = os.getenv(\"MACRO_PATH\", '/macro')\n",
    "OPTIONS_PATH = os.getenv(\"OPTIONS_PATH\", '/options')\n",
    "LLM_OUTPUT_PATH = os.getenv(\"LLM_OUTPUT_PATH\", '/llm_data')\n",
    "# LLM_OUTPUT_PATH = f\"{LLM_OUTPUT_PATH}/fast\"\n",
    "LOGS_PATH = os.getenv(\"LOGS_PATH\", '/logs')\n",
    "paths = [LLM_OUTPUT_PATH, LOGS_PATH]\n",
    "for path in paths:\n",
    "    if path and not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n",
    "    logging.info(\"Running in Kaggle...\")\n",
    "\n",
    "    DATA_PATH = \"/kaggle/input/thesis/data\"\n",
    "    FUNDAMENTALS_PATH = DATA_PATH + FUNDAMENTALS_PATH\n",
    "    HISTORIC_PATH = DATA_PATH + HISTORIC_PATH\n",
    "    MACRO_PATH = DATA_PATH + MACRO_PATH\n",
    "    OPTIONS_PATH = DATA_PATH + OPTIONS_PATH\n",
    "    LLM_PROMPTS_PATH = DATA_PATH + LLM_PROMPTS_PATH\n",
    "    sys.path.insert(1, \"/kaggle/usr/lib/rl_agent_utils\")\n",
    "    sys.path.insert(1, \"/kaggle/usr/lib/data_utils\")\n",
    "else:\n",
    "    DATA_PATH = './data'\n",
    "    module_path = os.path.abspath(os.path.join(os.getcwd(), 'utils'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\") # \"gpt-4.1-nano\" #\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "STARTDATE = '2018-01-01'\n",
    "ENDDATE = '2020-01-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stock_data(ticker):\n",
    "    input_file = f\"{HISTORIC_PATH}/engineered_{ticker}_data.parquet\"\n",
    "\n",
    "    start_date = pd.to_datetime(STARTDATE, utc=True)\n",
    "    end_date = pd.to_datetime(ENDDATE, utc=True)\n",
    "\n",
    "    engineered_df = pd.read_parquet(input_file)\n",
    "    engineered_df.set_index('Date', inplace=True)\n",
    "    engineered_df = engineered_df[(engineered_df.index >= start_date) & (engineered_df.index <= end_date)]\n",
    "\n",
    "    return engineered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm_trade_experiment(ticker_df,\n",
    "                              ticker,\n",
    "                              prompt_version,\n",
    "                              risk_version,\n",
    "                              prompt_path=LLM_PROMPTS_PATH,\n",
    "                              output_path=LLM_OUTPUT_PATH,\n",
    "                              client=OPENAI_CLIENT,\n",
    "                              model=OPENAI_MODEL,\n",
    "                              start_date=STARTDATE,\n",
    "                              end_date=ENDDATE,\n",
    "                              news_yaml_file=None,\n",
    "                              plot=True):\n",
    "    results_dir = f'{output_path}/results/{risk_version}/{prompt_version}/{ticker}'\n",
    "    figures_dir = f'{output_path}/figures/{risk_version}/{prompt_version}/{ticker}'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    os.makedirs(figures_dir, exist_ok=True)\n",
    "\n",
    "    results_file = os.path.join(results_dir, 'llm_results.json')\n",
    "    data_file = os.path.join(results_dir, 'llm_data.csv')\n",
    "    fig1_file = f\"{figures_dir}/fig1_llm_trade_analysis.png\"\n",
    "    fig2_file = f\"{figures_dir}/fig2_llm_trading_signals.png\"\n",
    "    fig3_file = f\"{figures_dir}/fig3_llm_distributions.png\"\n",
    "    fig4_file = f\"{figures_dir}/fig4_llm_evaluations.png\"\n",
    "\n",
    "    if os.path.exists(results_file) and os.path.exists(data_file) and all(os.path.exists(f) for f in [fig1_file, fig2_file, fig3_file]):\n",
    "        with open(results_file, 'r') as f:\n",
    "            llm_trading_metrics = json.load(f)\n",
    "        llm_trades_df = pd.read_csv(data_file)\n",
    "    else:\n",
    "        output_dir = f'{output_path}/response/{risk_version}/{prompt_version}'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        llm_trades_df = generate_strategy_for_ticker(\n",
    "                                    ticker_df=ticker_df,\n",
    "                                    ticker=ticker,\n",
    "                                    LLM_OUTPUT_PATH=output_dir,\n",
    "                                    persona=PERSONA,\n",
    "                                    HIGH_RISK_PROFILE=HIGH_RISK_PROFILE if risk_version == 'r' else LOW_RISK_PROFILE,\n",
    "                                    HIGH_OBJECTIVES=HIGH_OBJECTIVES if risk_version == 'r' else LOW_OBJECTIVES,\n",
    "                                    client=client,\n",
    "                                    model=model,\n",
    "                                    strategy_yaml_file=f'{prompt_path}/strat_prompt_{prompt_version}.yml',\n",
    "                                    news_yaml_file=f'{prompt_path}/{news_yaml_file}' if news_yaml_file else None,\n",
    "                                    start_date=start_date,\n",
    "                                    end_date=end_date,\n",
    "                                    max_news=5 if news_yaml_file else 0,\n",
    "                                    time_horizon='monthly',\n",
    "                                )\n",
    "        llm_trading_metrics, llm_trades_df = evaluate_trading_metrics(llm_trades_df)\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(llm_trading_metrics, f, indent=4)\n",
    "        llm_trades_df.to_csv(data_file, index=False, quoting=csv.QUOTE_MINIMAL, escapechar='\\\\')\n",
    "        fig1, fig3, fig2 = plot_llm_trade(llm_trades_df, plot=plot)\n",
    "        fig1.savefig(fig1_file, dpi=300, bbox_inches='tight')\n",
    "        fig2.savefig(fig2_file, dpi=300, bbox_inches='tight')\n",
    "        fig3.savefig(fig3_file, dpi=300, bbox_inches='tight')\n",
    "    return llm_trading_metrics, llm_trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'TSLA'\n",
    "output_path='./spottest'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "engineered_df = load_stock_data(TARGET)\n",
    "llm_trading_metrics, llm_trades_df = run_llm_trade_experiment(ticker_df = engineered_df,\n",
    "                                                                output_path=LLM_OUTPUT_PATH,\n",
    "                                                                ticker = TARGET,\n",
    "                                                                prompt_version = 'v4',\n",
    "                                                                news_yaml_file=\"analyst_prompt_v1.yml\",\n",
    "                                                                start_date=STARTDATE,\n",
    "                                                                end_date=ENDDATE,\n",
    "                                                                risk_version = 'r',\n",
    "                                                                model=OPENAI_MODEL\n",
    "                                                            )\n",
    "llm_trading_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\", \"AMZN\", \"META\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for risk in ['r', 'nr']:\n",
    "    for ticker in tqdm(TICKERS):\n",
    "        engineered_df = load_stock_data(ticker)\n",
    "        llm_trading_metrics, llm_trades_df = run_llm_trade_experiment(ticker_df = engineered_df,\n",
    "                                                                        ticker = ticker,\n",
    "                                                                        prompt_version = 'v1',\n",
    "                                                                        risk_version = risk,\n",
    "                                                                        plot=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for risk in ['r', 'nr']:\n",
    "    for ticker in tqdm(TICKERS):\n",
    "        engineered_df = load_stock_data(ticker)\n",
    "        llm_trading_metrics, llm_trades_df = run_llm_trade_experiment(ticker_df = engineered_df,\n",
    "                                                                        ticker = ticker,\n",
    "                                                                        prompt_version = 'v2',\n",
    "                                                                        risk_version = risk,\n",
    "                                                                        plot=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for risk in ['r', 'nr']:\n",
    "    for ticker in tqdm(TICKERS):\n",
    "        engineered_df = load_stock_data(ticker)\n",
    "        llm_trading_metrics, llm_trades_df = run_llm_trade_experiment(ticker_df = engineered_df,\n",
    "                                                                        ticker = ticker,\n",
    "                                                                        prompt_version = 'v3',\n",
    "                                                                        risk_version = risk,\n",
    "                                                                        plot=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for risk in ['r', 'nr']:\n",
    "    for ticker in tqdm(TICKERS):\n",
    "        engineered_df = load_stock_data(ticker)\n",
    "        llm_trading_metrics, llm_trades_df = run_llm_trade_experiment(ticker_df = engineered_df,\n",
    "                                                                        ticker = ticker,\n",
    "                                                                        prompt_version = 'v4',\n",
    "                                                                        news_yaml_file=\"analyst_prompt_v1.yml\",\n",
    "                                                                        risk_version = risk,\n",
    "                                                                        plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate and Analyze All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_profiles = [\"r\", \"nr\"]\n",
    "prompt_versions = [\"v1\", \"v2\", \"v3\", \"v4\"]\n",
    "data = []\n",
    "\n",
    "for risk_profile in risk_profiles:\n",
    "    for version in prompt_versions:\n",
    "        for ticker in TICKERS:\n",
    "            folder_path = os.path.join(LLM_OUTPUT_PATH, \"results\", risk_profile, version, ticker)\n",
    "            json_file_path = os.path.join(folder_path, \"llm_results.json\")\n",
    "\n",
    "            # Check if the JSON file exists\n",
    "            if os.path.exists(json_file_path):\n",
    "                # Load JSON data\n",
    "                with open(json_file_path, 'r') as file:\n",
    "                    results = json.load(file)\n",
    "                    results['Risk Profile'] = \"High Risk\" if risk_profile == \"r\" else \"Low Risk\"\n",
    "                    results['Prompt Version'] = version\n",
    "                    results['Ticker'] = ticker\n",
    "                    data.append(results)\n",
    "\n",
    "results_df = pd.DataFrame(data)\n",
    "results_df.tail(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "pivot_table = (\n",
    "    results_df[results_df[\"Risk Profile\"] == \"High Risk\"]\n",
    "    .pivot_table(\n",
    "        values=[\"Sharpe Ratio (Annualized SR)\", \"Mean Perplexity\", \"Mean Entropy\", \"Maximum Drawdown (MDD)\"],\n",
    "        index=\"Ticker\",\n",
    "        columns=\"Prompt Version\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    ")\n",
    "\n",
    "pivot_table = pivot_table.sort_index(axis=1, level=1)\n",
    "pprint(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    results_df[results_df[\"Risk Profile\"] == \"High Risk\"]\n",
    "    .groupby(\"Prompt Version\")[[\"Sharpe Ratio (Annualized SR)\", \"Mean Perplexity\", \"Mean Entropy\", \"Maximum Drawdown (MDD)\"]]\n",
    "    .mean()\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = (\n",
    "    results_df[results_df[\"Risk Profile\"] == \"Low Risk\"]\n",
    "    .pivot_table(\n",
    "        values=[\"Sharpe Ratio (Annualized SR)\", \"Mean Perplexity\", \"Mean Entropy\"],\n",
    "        index=\"Ticker\",\n",
    "        columns=\"Prompt Version\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    ")\n",
    "\n",
    "pivot_table = pivot_table.sort_index(axis=1, level=1)\n",
    "pprint(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    results_df[results_df[\"Risk Profile\"] == \"Low Risk\"]\n",
    "    .groupby(\"Prompt Version\")[[\"Sharpe Ratio (Annualized SR)\", \"Mean Perplexity\", \"Mean Entropy\"]]\n",
    "    .mean()\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5722911,
     "sourceId": 9421991,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 197612253,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "quant_drl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1234.187031,
   "end_time": "2024-09-17T20:07:16.406924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-17T19:46:42.219893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
