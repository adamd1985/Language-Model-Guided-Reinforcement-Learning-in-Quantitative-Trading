{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Expert Reviewer Survey Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the material for the surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:39:13.829574Z",
     "iopub.status.busy": "2024-09-23T14:39:13.829218Z",
     "iopub.status.idle": "2024-09-23T14:39:14.190909Z",
     "shell.execute_reply": "2024-09-23T14:39:14.189908Z",
     "shell.execute_reply.started": "2024-09-23T14:39:13.829533Z"
    },
    "papermill": {
     "duration": 0.761376,
     "end_time": "2024-09-17T19:46:45.797391",
     "exception": false,
     "start_time": "2024-09-17T19:46:45.036015",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "INSTALL_DEPS = False\n",
    "if INSTALL_DEPS:\n",
    "    %pip install python-dotenv==1.0.1\n",
    "    %pip install tqdm==4.66.5\n",
    "    %pip install openai==1.58.1\n",
    "    %pip install matplotlib reportlab tabulate\n",
    "\n",
    "%load_ext dotenv\n",
    "\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\", '/fundamentals')\n",
    "LLM_PROMPTS_PATH = os.getenv(\"LLM_PROMPTS_PATH\", '/prompts')\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\", '/fundamentals')\n",
    "HISTORIC_PATH = os.getenv(\"HISTORIC_PATH\", '/historic')\n",
    "MACRO_PATH = os.getenv(\"MACRO_PATH\", '/macro')\n",
    "OPTIONS_PATH = os.getenv(\"OPTIONS_PATH\", '/options')\n",
    "LLM_OUTPUT_PATH = os.getenv(\"LLM_OUTPUT_PATH\", '/llm_data')\n",
    "LLM_OUTPUT_PATH = f\"judge_reviews/{LLM_OUTPUT_PATH}\"\n",
    "LOGS_PATH = os.getenv(\"LOGS_PATH\", '/logs')\n",
    "paths = [LLM_OUTPUT_PATH, LOGS_PATH]\n",
    "for path in paths:\n",
    "    if path and not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n",
    "    logging.info(\"Running in Kaggle...\")\n",
    "\n",
    "    DATA_PATH = \"/kaggle/input/thesis/data\"\n",
    "    FUNDAMENTALS_PATH = DATA_PATH + FUNDAMENTALS_PATH\n",
    "    HISTORIC_PATH = DATA_PATH + HISTORIC_PATH\n",
    "    MACRO_PATH = DATA_PATH + MACRO_PATH\n",
    "    OPTIONS_PATH = DATA_PATH + OPTIONS_PATH\n",
    "    LLM_PROMPTS_PATH = DATA_PATH + LLM_PROMPTS_PATH\n",
    "    sys.path.insert(1, \"/kaggle/usr/lib/rl_agent_utils\")\n",
    "    sys.path.insert(1, \"/kaggle/usr/lib/data_utils\")\n",
    "else:\n",
    "    DATA_PATH = './data'\n",
    "    module_path = os.path.abspath(os.path.join(os.getcwd(), 'utils'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "from openai import OpenAI\n",
    "from data_utils import generate_strategy_for_ticker, evaluate_trading_metrics, sanitize_text, HIGH_RISK_PROFILE, HIGH_OBJECTIVES , PERSONA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_EXPERIMENT = 'r'\n",
    "PROMPT_VERSION = 'v3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_first_business_day(date_str):\n",
    "    date = pd.to_datetime(date_str, utc=True).normalize()\n",
    "    return date + pd.offsets.BMonthBegin(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_strategy_analysis(data, strategy_freq='M', llm_trade_action=None, output_dir='./judges_handbook'):\n",
    "    plot_data = data # if strategy_freq == 'W' else data.resample('W').last().ffill()\n",
    "    fig1, axes1 = plt.subplots(4, 1, figsize=(16, 8), gridspec_kw={'height_ratios': [3, 1, 1, 1]}, sharex=True)\n",
    "\n",
    "    # Price & Technical Indicators\n",
    "    ax = axes1[0]\n",
    "    ax.set_title(\"Price with Technical Indicators\", fontsize=16)\n",
    "    ax.plot(plot_data.index, plot_data['Close'], label='Weekly Close', color='blue', linewidth=2.5)\n",
    "    ax.plot(plot_data.index, plot_data['20MA'], label='20 Day MA', color='gray', linestyle=\"--\", linewidth=2)\n",
    "    ax.plot(plot_data.index, plot_data['200MA'], label='200 Day MA', color='black', linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    if 'BB_Upper' in plot_data.columns and 'BB_Lower' in plot_data.columns:\n",
    "        ax.fill_between(plot_data.index, plot_data['BB_Upper'], plot_data['BB_Lower'], color='blue', alpha=0.1, label='Bollinger Bands')\n",
    "    ax.fill_between(plot_data.index, plot_data['Close'] + plot_data['ATR'], plot_data['Close'] - plot_data['ATR'],\n",
    "                    color='gray', alpha=0.3, label=\"ATR Range\")\n",
    "\n",
    "    if llm_trade_action is not None:\n",
    "        ranges = np.concatenate([plot_data['Close'], plot_data['20MA'], plot_data['200MA']])\n",
    "        decision_price = data['Close'].iloc[0]\n",
    "        ax.axhline(decision_price, color='green', linewidth=2, label=f'LLM {llm_trade_action} Entry')\n",
    "        if llm_trade_action == \"LONG\":\n",
    "            ax.fill_between(plot_data.index, decision_price, np.max(ranges), color='lightgreen', alpha=0.15, label=\"Profit Zone\")\n",
    "            ax.fill_between(plot_data.index, np.min(ranges), decision_price, color='lightcoral', alpha=0.15, label=\"Loss Zone\")\n",
    "        elif llm_trade_action == \"SHORT\":\n",
    "            ax.fill_between(plot_data.index, decision_price, np.max(ranges), color='lightcoral', alpha=0.15, label=\"Loss Zone\")\n",
    "            ax.fill_between(plot_data.index, np.min(ranges), decision_price, color='lightgreen', alpha=0.15, label=\"Profit Zone\")\n",
    "\n",
    "    ax.set_ylabel(\"Price (USD)\")\n",
    "    ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Liquidity Metrics (Volume)\n",
    "    ax = axes1[1]\n",
    "    ax.set_title(\"Liquidity Metrics\", fontsize=14)\n",
    "    ax.bar(plot_data.index, plot_data['Volume'], label='Volume', color='gray', alpha=0.6)\n",
    "    ax.set_ylabel(\"Volume\")\n",
    "    ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Relative Strength Index (RSI)\n",
    "    ax = axes1[2]\n",
    "    ax.set_title(\"Relative Strength Index (RSI)\", fontsize=14)\n",
    "    if 'RSI' in plot_data.columns:\n",
    "        ax.plot(plot_data.index, plot_data['RSI'], label='RSI', color='blue', linewidth=2.5)\n",
    "        ax.axhline(70, color='red', linestyle='--', linewidth=1, label='Overbought (70)')\n",
    "        ax.axhline(30, color='green', linestyle='--', linewidth=1, label='Oversold (30)')\n",
    "    ax.set_ylabel(\"RSI (0-100)\")\n",
    "    ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    # MACD Indicator\n",
    "    ax = axes1[3]\n",
    "    ax.set_title(\"MACD\", fontsize=14)\n",
    "    if 'MACD' in plot_data.columns and 'Signal_Line' in plot_data.columns:\n",
    "        ax.plot(plot_data.index, plot_data['MACD'], label='MACD', color='blue', linewidth=2.5)\n",
    "        ax.plot(plot_data.index, plot_data['Signal_Line'], label='Signal Line', color='red', linewidth=2)\n",
    "    ax.set_ylabel(\"MACD Value\")\n",
    "    ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    fig2, axes2 = plt.subplots(3, 1, figsize=(16, 8), gridspec_kw={'height_ratios': [2, 1, 2]})\n",
    "\n",
    "    ax = axes2[0]\n",
    "    ax.set_title(\"Option Implied Volatility\", fontsize=16)\n",
    "    if 'ATM_IV_Call' in plot_data.columns and 'ATM_IV_Put' in plot_data.columns:\n",
    "        ax.plot(plot_data.index, plot_data['ATM_IV_Call'], label='ATM Call', linewidth=1.5, alpha=0.5)\n",
    "        ax.plot(plot_data.index, plot_data['ATM_IV_Put'], label='ATM Put', linewidth=1.5, alpha=0.5)\n",
    "        ax.plot(plot_data.index, plot_data['OTM_IV_Call'], label='OTM Call', linewidth=1.5, linestyle='-.', alpha=0.5)\n",
    "        ax.plot(plot_data.index, plot_data['OTM_IV_Put'], label='OTM Put', linewidth=1.5, linestyle='-.', alpha=0.5)\n",
    "    ax.set_ylabel(\"Implied Volatility (%)\")\n",
    "    ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axes2[1]\n",
    "    ax.set_title(\"Option Put Skew\", fontsize=16)\n",
    "    if 'ATM_Skew' in plot_data.columns and 'OTM_Skew' in plot_data.columns:\n",
    "        ax.plot(plot_data.index, plot_data['ATM_Skew'], label='ATM Skew', linewidth=2.5, color='blue')\n",
    "        ax.plot(plot_data.index, plot_data['OTM_Skew'], label='OTM Skew', linewidth=2.5, linestyle='--', color='red')\n",
    "    ax.set_ylabel(\"IV Skew)\")\n",
    "\n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=2, alpha=0.8, label=\"Skew Threshold\")\n",
    "    ranges = np.concatenate([plot_data['ATM_Skew'], plot_data['OTM_Skew'], [0.25]])\n",
    "    ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axes2[2]\n",
    "    ax.set_title(\"Market Volatility & Beta\", fontsize=16)\n",
    "    ax2 = ax.twinx()\n",
    "    if 'Market_Beta' in plot_data.columns:\n",
    "        ax.plot(plot_data.index, plot_data['Market_Beta'], label='Market Beta', color='orange', linewidth=2.5)\n",
    "    if 'VIX_Close' in plot_data.columns:\n",
    "        ax2.plot(plot_data.index, plot_data['VIX_Close'], label='VIX', color='purple', linewidth=2.5, linestyle=\"--\")\n",
    "    ax.set_ylabel(\"Market Beta\")\n",
    "    ax2.set_ylabel(\"VIX Level\")\n",
    "    ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "    ax2.legend(fontsize=12, loc=\"lower right\", bbox_to_anchor=(1.15, 1))\n",
    "    ax.grid(True)\n",
    "\n",
    "    for ax_group in [axes1, axes2]:\n",
    "        for ax in ax_group:\n",
    "            if llm_trade_action is None:\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "            else:\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "\n",
    "    if llm_trade_action is None:\n",
    "        fig3, axes3 = plt.subplots(3, 1, figsize=(16, 8), gridspec_kw={'height_ratios': [2, 1, 1]}, sharex=True)\n",
    "        ax = axes3[0]\n",
    "        ax.set_title(\"Macroeconomic Indicators\", fontsize=16)\n",
    "        econ_metrics = ['GDP_YoY', 'PPI_YoY', 'M2_Money_Supply_YoY', 'Housing_Starts_YoY',\n",
    "                        'Consumer_Confidence_YoY', 'Treasury_Yields_YoY', 'Employment_YoY']\n",
    "        for econ in econ_metrics:\n",
    "            if econ in plot_data.columns:\n",
    "                formatted_label = econ.replace(\"_YoY\", \"\").replace(\"_\", \" \")\n",
    "                ax.plot(plot_data.index, plot_data[econ], label=formatted_label, linewidth=2)\n",
    "        ax.set_ylabel(\"YoY Change (%)\")\n",
    "        ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "        ax.grid(True)\n",
    "        ax = axes3[1]\n",
    "        ax.set_title(\"ISM PMI\", fontsize=16)\n",
    "        ax.plot(plot_data.index, plot_data['PMI'], color='blue', linewidth=2, label=\"PMI\")\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(plot_data.index, plot_data['PMI_YoY'], color='red', linewidth=2, linestyle=\"--\", label=\"PMI YoY\")\n",
    "        ax.set_ylabel(\"PMI (0-100)\")\n",
    "        ax2.set_ylabel(\"YoY Change (%)\")\n",
    "        ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "        ax2.legend(fontsize=12, loc=\"lower right\", bbox_to_anchor=(1.15, 1))\n",
    "        ax.grid(True)\n",
    "\n",
    "        ax = axes3[2]\n",
    "        ax.set_title(\"Interest Rates & Yield Curve\", fontsize=16)\n",
    "        if 'Treasury_Yields_YoY' in plot_data.columns:\n",
    "            ax.plot(plot_data.index, plot_data['Treasury_Yields_YoY'], label='10yr Treasury Yields', color='blue', linewidth=2.5)\n",
    "            ax.plot(plot_data.index, plot_data['Yield_Curve_YoY'], label='Yield Curve', color='red', linewidth=2.5)\n",
    "            ax.axhline(y=0, color='black', linestyle='--', linewidth=2, alpha=0.8, label=\"Inversion Threshold\")\n",
    "        ax.set_ylabel(\"YoY Change (%)\")\n",
    "        ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "        ax.grid(True)\n",
    "\n",
    "        fig4, axes4 = plt.subplots(3, 1, figsize=(16, 8), gridspec_kw={'height_ratios': [2, 1, 1]}, sharex=True)\n",
    "        ax = axes4[0]\n",
    "        ax.set_title(\"Fundamental Indicators\", fontsize=16)\n",
    "        fundamentals_qoq = ['Quick_Ratio_QoQ_Growth', 'Current_Ratio_QoQ_Growth', 'Debt_to_Equity_Ratio_QoQ_Growth',\n",
    "                            'Gross_Margin_QoQ_Growth', 'Operating_Margin_QoQ_Growth', 'EBIT_Margin_QoQ_Growth',\n",
    "                            'Net_Profit_Margin_QoQ_Growth', 'Asset_Turnover_QoQ_Growth', 'Inventory_Turnover_Ratio_QoQ_Growth']\n",
    "        for metric in fundamentals_qoq:\n",
    "            if metric in plot_data.columns:\n",
    "                formatted_label = metric.replace(\"_QoQ_Growth\", \"\").replace(\"_\", \" \")\n",
    "                ax.plot(plot_data.index, plot_data[metric], label=formatted_label, linewidth=2)\n",
    "        ax.set_ylabel(\"QoQ Growth (%)\")\n",
    "        ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "        ax.grid(True)\n",
    "        ax = axes4[1]\n",
    "        ax.set_title(\"Valuation & Profitability\", fontsize=16)\n",
    "        valuation_qoq = ['Price_to_Book_Ratio_QoQ_Growth', 'PE_Ratio_QoQ_Growth', 'EPS_QoQ_Growth',\n",
    "                        'Net_Income_QoQ_Growth', 'Free_Cash_Flow_Per_Share_QoQ_Growth']\n",
    "        for metric in valuation_qoq:\n",
    "            if metric in plot_data.columns:\n",
    "                formatted_label = metric.replace(\"_QoQ_Growth\", \"\").replace(\"_\", \" \")\n",
    "                ax.plot(plot_data.index, plot_data[metric], label=formatted_label, linewidth=2)\n",
    "        ax.set_ylabel(\"QoQ Growth (%)\")\n",
    "        ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "        ax.grid(True)\n",
    "        ax = axes4[2]\n",
    "        ax.set_title(\"Returns & Cash Flow\", fontsize=16)\n",
    "        returns_qoq = ['Operating_Cash_Flow_Per_Share_QoQ_Growth', 'Return_on_Equity_QoQ_Growth', 'Return_on_Assets_QoQ_Growth']\n",
    "        for metric in returns_qoq:\n",
    "            if metric in plot_data.columns:\n",
    "                formatted_label = metric.replace(\"_QoQ_Growth\", \"\").replace(\"_\", \" \")\n",
    "                ax.plot(plot_data.index, plot_data[metric], label=formatted_label, linewidth=2)\n",
    "        ax.set_ylabel(\"QoQ Growth (%)\")\n",
    "        ax.legend(fontsize=12, loc=\"upper right\", bbox_to_anchor=(1.15, 1))\n",
    "        ax.grid(True)\n",
    "\n",
    "        for ax_group in [axes3, axes4]:\n",
    "            for ax in ax_group:\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "\n",
    "        for fig in [fig1, fig2, fig3, fig4]:\n",
    "            fig.tight_layout()\n",
    "    else:\n",
    "        for fig in [fig1, fig2]:\n",
    "            fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return [fig1, fig2, fig3, fig4] if llm_trade_action is None else [fig1, fig2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_data_before_decision(data, macro_columns, freq='M'):\n",
    "    if freq == 'M':\n",
    "        resample_freq = 'W'\n",
    "        periods_to_keep = -12\n",
    "    else:\n",
    "        resample_freq = 'D'\n",
    "        periods_to_keep = -30\n",
    "\n",
    "    aggregated_data = data.resample(resample_freq).agg({\n",
    "        'Close': ['first', 'last', 'max', 'min'],\n",
    "        'High': 'max',\n",
    "        'Low': 'min',\n",
    "        'ATR': ['mean', 'std', 'max', 'min'],\n",
    "        'Volume': ['sum', 'mean'],\n",
    "        'RSI': 'mean',\n",
    "        'Close_Slope': 'mean',\n",
    "        'Close_Z': 'mean'\n",
    "    }).fillna(0)\n",
    "\n",
    "    aggregated_data.columns = ['_'.join(col).strip() for col in aggregated_data.columns]\n",
    "    aggregated_data = aggregated_data.iloc[periods_to_keep:]\n",
    "\n",
    "    # Volatility & Risk Insights\n",
    "    volatility_metrics = aggregated_data[['ATR_mean', 'ATR_std', 'ATR_max', 'ATR_min']].rename(columns={\n",
    "        'ATR_mean': 'Average ATR',\n",
    "        'ATR_std': 'ATR Standard Deviation',\n",
    "        'ATR_max': 'Maximum ATR',\n",
    "        'ATR_min': 'Minimum ATR',\n",
    "    })\n",
    "\n",
    "    # Liquidity Insights\n",
    "    volume_metrics = aggregated_data[['Volume_sum', 'Volume_mean']].rename(columns={\n",
    "        'Volume_sum': 'Total Volume',\n",
    "        'Volume_mean': 'Average Volume',\n",
    "    })\n",
    "\n",
    "    # Macro Trends\n",
    "    macro_trends = {macro: data[macro].resample(resample_freq).last().pct_change().fillna(0).iloc[periods_to_keep:] * 100\n",
    "                    for macro in macro_columns if macro in data.columns}\n",
    "    macro_trends_df = pd.DataFrame(macro_trends, index=aggregated_data.index)\n",
    "\n",
    "    # Fundamental Metrics\n",
    "    fundamental_metrics = {metric: data[metric].resample(resample_freq).last().iloc[periods_to_keep:]\n",
    "                           for metric in [\n",
    "                               'EPS_YoY_Growth', 'EBITDA_YoY_Growth', 'PE_Ratio_YoY_Growth',\n",
    "                               'Net_Income_YoY_Growth', 'Free_Cash_Flow_Per_Share_YoY_Growth',\n",
    "                               'Operating_Margin_YoY_Growth', 'Debt_to_Equity_Ratio_YoY_Growth',\n",
    "                               'Return_on_Assets_YoY_Growth', 'Return_on_Equity_YoY_Growth'\n",
    "                           ] if metric in data.columns}\n",
    "    fundamentals_df = pd.DataFrame(fundamental_metrics, index=aggregated_data.index)\n",
    "\n",
    "    # Economic Indicators\n",
    "    economic_indicators = {econ: data[econ].resample(resample_freq).last().iloc[periods_to_keep:]\n",
    "                           for econ in [\n",
    "                               'PMI_YoY', 'GDP_YoY', 'Treasury_Yields_YoY', 'Housing_Starts_YoY',\n",
    "                               'Consumer_Confidence_YoY', 'Employment_YoY', 'Retail_Sales_YoY',\n",
    "                               'CPI_YoY', 'PPI_YoY', 'M2_Money_Supply_YoY'\n",
    "                           ] if econ in data.columns}\n",
    "    economic_df = pd.DataFrame(economic_indicators, index=aggregated_data.index)\n",
    "\n",
    "    # Market Performance vs. Benchmarks & Sector\n",
    "    market_performance = {benchmark: data[benchmark].resample(resample_freq).last().pct_change().fillna(0).iloc[periods_to_keep:] * 100\n",
    "                          for benchmark in ['SPX_Close', 'NDX_Close', 'VIX_Close', 'TNX_Close']\n",
    "                          if benchmark in data.columns}\n",
    "    market_trends_df = pd.DataFrame(market_performance, index=aggregated_data.index)\n",
    "\n",
    "    # Option Volatility Metrics (ATM IV)\n",
    "    option_metrics = {iv_metric: data[iv_metric].resample(resample_freq).last().iloc[periods_to_keep:]\n",
    "                      for iv_metric in ['ATM_IV_Call', 'ATM_IV_Put']\n",
    "                      if iv_metric in data.columns}\n",
    "    option_vol_df = pd.DataFrame(option_metrics, index=aggregated_data.index)\n",
    "\n",
    "    # Credit & Debt Risk Metrics\n",
    "    credit_risk_metrics = {metric: data[metric].resample(resample_freq).last().iloc[periods_to_keep:]\n",
    "                           for metric in ['Debt_to_Equity_Ratio', 'Interest_Coverage_Ratio', 'Current_Ratio', 'Quick_Ratio']\n",
    "                           if metric in data.columns}\n",
    "    credit_risk_df = pd.DataFrame(credit_risk_metrics, index=aggregated_data.index)\n",
    "\n",
    "    # Generate Report for ML Handbook\n",
    "    report = \"\\n\"\n",
    "    report += \"### Market and Financial Data Summary for ML Model\\n\"\n",
    "    report += \"\\n#### Volatility & Risk Insights\\n\"\n",
    "    report += tabulate(volatility_metrics, headers=\"keys\", tablefmt=\"grid\") + \"\\n\\n\"\n",
    "    report += \"#### Volume & Liquidity Insights\\n\"\n",
    "    report += tabulate(volume_metrics, headers=\"keys\", tablefmt=\"grid\") + \"\\n\\n\"\n",
    "    report += \"#### Macro Trends\\n\"\n",
    "    report += tabulate(macro_trends_df, headers=\"keys\", tablefmt=\"grid\") + \"\\n\\n\"\n",
    "    report += \"#### Market Performance & Benchmarks\\n\"\n",
    "    report += tabulate(market_trends_df, headers=\"keys\", tablefmt=\"grid\") + \"\\n\\n\"\n",
    "    report += \"#### Fundamental Growth & Valuation Metrics\\n\"\n",
    "    report += tabulate(fundamentals_df, headers=\"keys\", tablefmt=\"grid\") + \"\\n\\n\"\n",
    "    report += \"#### Economic Indicators\\n\"\n",
    "    report += tabulate(economic_df, headers=\"keys\", tablefmt=\"grid\") + \"\\n\\n\"\n",
    "    report += \"#### Option Volatility (ATM Calls & Puts)\\n\"\n",
    "    report += tabulate(option_vol_df, headers=\"keys\", tablefmt=\"grid\") + \"\\n\\n\"\n",
    "    report += \"#### Credit & Debt Risk Metrics\\n\"\n",
    "    report += tabulate(credit_risk_df, headers=\"keys\", tablefmt=\"grid\") + \"\\n\"\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge Handbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def save_stacked_figures(figures, role, output_dir, scale_factor=3, dpi=600):\n",
    "    \"\"\"\n",
    "    Combines multiple figures into a vertically stacked layout, removes white space, and enhances resolution.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Determine total height needed for stacking\n",
    "    fig_heights = []\n",
    "    fig_images = []\n",
    "\n",
    "    for fig_source in figures:\n",
    "        fig_source.canvas.draw()\n",
    "        img = np.array(fig_source.canvas.buffer_rgba())\n",
    "\n",
    "        # Remove whitespace\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_cropped = img_pil.crop(img_pil.getbbox())\n",
    "\n",
    "        # Scale up the resolution\n",
    "        new_size = (img_cropped.width * scale_factor, img_cropped.height * scale_factor)\n",
    "        img_resized = img_cropped.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "        fig_images.append(img_resized)\n",
    "        fig_heights.append(img_resized.height)\n",
    "\n",
    "    # Create a single stacked image\n",
    "    total_height = sum(fig_heights)\n",
    "    max_width = max(img.width for img in fig_images)\n",
    "\n",
    "    stacked_img = Image.new(\"RGBA\", (max_width, total_height), (255, 255, 255, 0))\n",
    "\n",
    "    y_offset = 0\n",
    "    for img in fig_images:\n",
    "        stacked_img.paste(img, (0, y_offset))\n",
    "        y_offset += img.height\n",
    "\n",
    "    # Save the optimized stacked image\n",
    "    filename = f\"{role}_stacked_optimized.png\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    stacked_img.save(filepath, dpi=(dpi, dpi))\n",
    "\n",
    "    print(f\"Saved optimized stacked figure: {filepath}\")\n",
    "\n",
    "    return filepath\n",
    "\n",
    "def calculate_llm_cost(model, prompt_tokens, completion_tokens):\n",
    "    \"\"\"Calculate the cost of LLM execution based on token usage and model pricing.\"\"\"\n",
    "    pricing = {\n",
    "        \"o1-mini\": {\"input_price\": 3.00 / 1e6, \"output_price\": 12.00 / 1e6},  # Per million tokens\n",
    "        \"GPT-4o-mini\": {\"input_price\": 0.15 / 1e6, \"output_price\": 0.60 / 1e6},\n",
    "        \"deepseek-chat\": {\"input_price\": 0.014 / 1e6, \"output_price\": 0.14 / 1e6},\n",
    "        \"deepseek-reasoner\": {\"input_price\": 0.055 / 1e6, \"output_price\": 0.219 / 1e6},\n",
    "    }\n",
    "\n",
    "    # Default to GPT-4o-mini if model not specified\n",
    "    model_prices = pricing.get(model, pricing[\"GPT-4o-mini\"])\n",
    "    input_cost = prompt_tokens * model_prices[\"input_price\"]\n",
    "    output_cost = completion_tokens * model_prices[\"output_price\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    return input_cost, output_cost, total_cost\n",
    "\n",
    "\n",
    "def print_performance_metrics(trading_metrics, llm_trades, model_name=\"GPT-4o-mini\"):\n",
    "    \"\"\"Return formatted trading performance metrics as a string while also printing them.\"\"\"\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # Tabulate performance metrics\n",
    "    metrics_table = tabulate(\n",
    "        [[k, v] for k, v in trading_metrics.items()],\n",
    "        headers=[\"Metric\", \"Value\"],\n",
    "        tablefmt=\"grid\"\n",
    "    )\n",
    "    output.append(\"\\n=== Performance Metrics ===\\n\")\n",
    "    output.append(metrics_table)\n",
    "\n",
    "    # Extract LLM probabilities and token usage\n",
    "    llm_probs = {\n",
    "        \"Long Probability\": llm_trades.get(\"long_conf_score\", \"N/A\").iloc[-1],\n",
    "        \"Short Probability\": llm_trades.get(\"short_conf_score\", \"N/A\").iloc[-1],\n",
    "        \"Long Token strategy\": llm_trades.get(\"long_token_proba\", \"N/A\").iloc[-1],\n",
    "        \"Short Token strategy\": llm_trades.get(\"short_token_proba\", \"N/A\").iloc[-1],\n",
    "        \"Long Token Probability\": llm_trades.get(\"long_token_proba\", \"N/A\").iloc[-1],\n",
    "        \"Short Token Probability\": llm_trades.get(\"short_token_proba\", \"N/A\").iloc[-1],\n",
    "        \"Perplexity\": llm_trades.get(\"perplexity\", \"N/A\").iloc[-1],\n",
    "    }\n",
    "\n",
    "    tokens_meta_strat = llm_trades.get(\"tokens_meta_strat\", {}).iloc[-1]\n",
    "    tokens_meta_news = llm_trades.get(\"tokens_meta_news\", {}).iloc[-1]\n",
    "    tokens_meta_proba = llm_trades.get(\"tokens_meta_proba\", {}).iloc[-1]\n",
    "    tokens_meta_strat = tokens_meta_strat if isinstance(tokens_meta_strat, dict) else {}\n",
    "    tokens_meta_news = tokens_meta_news if isinstance(tokens_meta_news, dict) else {}\n",
    "    tokens_meta_proba = tokens_meta_proba if isinstance(tokens_meta_proba, dict) else {}\n",
    "\n",
    "    # Extract total tokens from all ensemble components\n",
    "    prompt_tokens_total = sum(meta.get(\"prompt_tokens\", 0) for meta in [tokens_meta_strat, tokens_meta_news, tokens_meta_proba])\n",
    "    completion_tokens_total = sum(meta.get(\"completion_tokens\", 0) for meta in [tokens_meta_strat, tokens_meta_news, tokens_meta_proba])\n",
    "    total_tokens = prompt_tokens_total + completion_tokens_total\n",
    "\n",
    "    # Calculate LLM execution costs for the ensemble\n",
    "    input_cost, output_cost, total_cost = calculate_llm_cost(model_name, prompt_tokens_total, completion_tokens_total)\n",
    "\n",
    "    # Tabulate LLM decision insights\n",
    "    llm_table = tabulate(\n",
    "        [[k, v] for k, v in llm_probs.items()],\n",
    "        headers=[\"LLM Decision Insights\", \"Value\"],\n",
    "        tablefmt=\"grid\"\n",
    "    )\n",
    "    output.append(\"\\n=== LLM Decision Insights ===\\n\")\n",
    "    output.append(llm_table)\n",
    "\n",
    "    # Tabulate token usage and cost analysis\n",
    "    token_table = tabulate(\n",
    "        [\n",
    "            [\"Prompt Tokens (Strategist)\", tokens_meta_strat.get(\"prompt_tokens\", 0)],\n",
    "            [\"Completion Tokens (Strategist)\", tokens_meta_strat.get(\"completion_tokens\", 0)],\n",
    "            [\"Prompt Tokens (Judge)\", tokens_meta_proba.get(\"prompt_tokens\", 0)],\n",
    "            [\"Completion Tokens (Judge)\", tokens_meta_proba.get(\"completion_tokens\", 0)],\n",
    "            [\"Prompt Tokens (News Analyst)\", tokens_meta_news.get(\"prompt_tokens\", 0)],\n",
    "            [\"Completion Tokens (News Analyst)\", tokens_meta_news.get(\"completion_tokens\", 0)],\n",
    "            [\"Total Prompt Tokens\", prompt_tokens_total],\n",
    "            [\"Total Completion Tokens\", completion_tokens_total],\n",
    "            [\"Total Tokens\", total_tokens],\n",
    "            [\"Input Cost (USD)\", f\"${input_cost:.6f}\"],\n",
    "            [\"Output Cost (USD)\", f\"${output_cost:.6f}\"],\n",
    "            [\"Total Cost (USD)\", f\"${total_cost:.6f}\"]\n",
    "        ],\n",
    "        headers=[\"Token Metrics\", \"Value\"],\n",
    "        tablefmt=\"grid\"\n",
    "    )\n",
    "    output.append(\"\\n=== Token Usage & Cost Analysis for Ensemble ===\\n\")\n",
    "    output.append(token_table)\n",
    "\n",
    "    # Join the output list into a single string\n",
    "    final_output = \"\\n\".join(output)\n",
    "\n",
    "    # Print and return the output\n",
    "    print(final_output)\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_strategy_evaluation(ticker=None,\n",
    "                                execution_freq=\"M\",\n",
    "                                role=\"judge\",\n",
    "                                start_date=None,\n",
    "                                end_date=None,\n",
    "                                strategy_yaml_file=f'{LLM_PROMPTS_PATH}/strat_prompt_{PROMPT_VERSION}.yml',\n",
    "                                news_yaml_file=None,\n",
    "                                client=OPENAI_CLIENT,\n",
    "                                model=OPENAI_MODEL,\n",
    "                                llm_output_path=LLM_OUTPUT_PATH,\n",
    "                                persona=PERSONA,\n",
    "                                objectives=HIGH_OBJECTIVES,\n",
    "                                risk=HIGH_RISK_PROFILE,\n",
    "                                HISTORIC_PATH=HISTORIC_PATH):\n",
    "\n",
    "    input_file = f\"{HISTORIC_PATH}/engineered_{ticker}_data.parquet\"\n",
    "    stock_df = pd.read_parquet(input_file)\n",
    "    stock_df.set_index('Date', inplace=True)\n",
    "\n",
    "    output_dir = f\"./judge_reviews/{ticker}_{execution_freq}_{model}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    llm_trades_df = generate_strategy_for_ticker(ticker_df=stock_df,\n",
    "                                                 ticker=ticker,\n",
    "                                                 LLM_OUTPUT_PATH=llm_output_path,\n",
    "                                                 persona=persona,\n",
    "                                                 HIGH_OBJECTIVES=objectives,\n",
    "                                                 HIGH_RISK_PROFILE=risk,\n",
    "                                                 client=client,\n",
    "                                                 model=model,\n",
    "                                                 strategy_yaml_file=strategy_yaml_file,\n",
    "                                                 news_yaml_file=news_yaml_file,\n",
    "                                                 start_date=start_date,\n",
    "                                                 end_date=end_date,\n",
    "                                                 max_news=5 if news_yaml_file is not None else 0)\n",
    "\n",
    "    _, llm_trades_df = evaluate_trading_metrics(llm_trades_df)\n",
    "    strategy_dates = (\n",
    "        llm_trades_df.index.to_series()\n",
    "        .dt.to_period(execution_freq)\n",
    "        .drop_duplicates()\n",
    "        .sort_values()\n",
    "        .dt.start_time\n",
    "        .dt.tz_localize(\"UTC\")\n",
    "    )\n",
    "    if len(strategy_dates) > 1:\n",
    "        strategy_dates = strategy_dates[:-1]\n",
    "\n",
    "    strategy_date = llm_trades_df.index.min()\n",
    "\n",
    "    # Loop until no more dates\n",
    "    while strategy_date <= llm_trades_df.index.max():\n",
    "        strategy_folder = os.path.join(output_dir, f\"{strategy_date.date()}\")\n",
    "        os.makedirs(strategy_folder, exist_ok=True)\n",
    "\n",
    "        historic_start_date = strategy_date - pd.DateOffset(years=1)\n",
    "        historic_end_date = strategy_date\n",
    "        effect_start_date = strategy_date\n",
    "        effect_end_date = strategy_date + pd.DateOffset(months=1)\n",
    "\n",
    "        historic_df = stock_df[(stock_df.index >= historic_start_date) & (stock_df.index < historic_end_date)]\n",
    "        effect_df = llm_trades_df[(llm_trades_df.index >= effect_start_date) & (llm_trades_df.index <= effect_end_date)]\n",
    "        llm_strategy_details = llm_trades_df.iloc[0]\n",
    "\n",
    "        trade_action, llm_explanation = \"No Trade\", \"No decision available.\"\n",
    "        if not llm_strategy_details.empty:\n",
    "            llm_decision = llm_strategy_details['trade_action']\n",
    "            llm_explanation = llm_strategy_details['explanation']\n",
    "            trade_action = \"LONG\" if llm_decision == 1 else \"SHORT\"\n",
    "\n",
    "        text_output = []\n",
    "\n",
    "        if role == \"judge\":\n",
    "            news = historic_df['content'].tail(10).dropna().apply(lambda x: sanitize_text(' '.join([str(i).strip() for i in x if str(i).strip()])))\n",
    "            news = news[news.str.strip() != ''].values\n",
    "\n",
    "            text_output.append(f\"\\n=== Judge's Evaluation: {ticker.upper()} - Market Data Until {strategy_date.date()} ===\\n\")\n",
    "            text_output.append(\"Based on the provided market data and news, predict the LLMâ€™s decision:\")\n",
    "            text_output.append(f\"News Factors Considered:\\n{news}\")\n",
    "\n",
    "            macro_columns = ['SPX_Close', 'NDX_Close', 'VIX_Close', 'TNX_Close', 'IRX_Close']\n",
    "            figures = plot_strategy_analysis(historic_df, strategy_freq=execution_freq, llm_trade_action=None)\n",
    "            save_figures(figures, role, strategy_folder)\n",
    "            save_stacked_figures(figures, role, strategy_folder)\n",
    "\n",
    "            summary_historic = summarize_data_before_decision(historic_df, macro_columns, freq=execution_freq)\n",
    "            text_output.append(f\"\\n=== Market Summary: {ticker.upper()} (Last 3 Months) ===\\n\")\n",
    "            text_output.append(summary_historic)\n",
    "\n",
    "        elif role == \"llm\":\n",
    "            text_output.append(f\"\\n=== {model} LLM Decision & Market Impact: {ticker.upper()} on {strategy_date.date()} ===\\n\")\n",
    "            text_output.append(f\"LLM Decision: {trade_action}\")\n",
    "            text_output.append(f\"Rationale: {llm_explanation}\")\n",
    "\n",
    "            if 'news_factors' in effect_df.columns and not effect_df.empty:\n",
    "                text_output.append(f\"News Factors Considered: {effect_df['news_factors'].iloc[0]}\")\n",
    "\n",
    "            figures = plot_strategy_analysis(effect_df, strategy_freq=execution_freq, llm_trade_action=trade_action)\n",
    "            save_figures(figures, role, strategy_folder)\n",
    "            save_stacked_figures(figures, role, strategy_folder)\n",
    "\n",
    "            effect_metrics, effect_df = evaluate_trading_metrics(effect_df)\n",
    "            text_output.append(print_performance_metrics(effect_metrics, effect_df, model))\n",
    "        next_date = pd.offsets.BMonthBegin().rollforward(strategy_date + pd.DateOffset(months=1))\n",
    "        if next_date > llm_trades_df.index.max():\n",
    "            break\n",
    "        strategy_date = next_date\n",
    "\n",
    "        with open(os.path.join(strategy_folder, f\"{role}_trade_summary.txt\"), \"w\") as f:\n",
    "            f.write('\\n'.join(text_output))\n",
    "\n",
    "\n",
    "def save_figures(figures, role, output_dir):\n",
    "    \"\"\" Saves generated figures into the output directory with appropriate titles. \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for fig in figures:\n",
    "        for ax in fig.axes:\n",
    "            title = ax.get_title()\n",
    "            if title:\n",
    "                filename = role + '_' + title.replace(\" \", \"_\").replace(\"/\", \"_\") + \".png\"\n",
    "                filepath = os.path.join(output_dir, filename)\n",
    "                fig.savefig(filepath, bbox_inches='tight')\n",
    "                print(f\"Saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = [\n",
    "    (\"TSLA\", \"2019-05-05\", \"2019-06-02\"),\n",
    "    (\"AAPL\", \"2019-04-07\", \"2019-05-05\"),\n",
    "    (\"GOOGL\", \"2019-11-04\", \"2019-12-02\"),\n",
    "    (\"MSFT\", \"2015-11-02\", \"2015-11-30\"),\n",
    "    (\"GOOGL\", \"2017-01-02\", \"2017-01-30\"),\n",
    "    (\"AAPL\", \"2015-01-05\", \"2015-02-02\"),\n",
    "]\n",
    "\n",
    "for index in range(len(trade_data)):\n",
    "    TARGET, STARTDATE, ENDDATE = trade_data[index]\n",
    "    print(TARGET, STARTDATE, ENDDATE)\n",
    "    execute_strategy_evaluation(role=\"judge\",\n",
    "                            ticker=TARGET,\n",
    "                            start_date=STARTDATE,\n",
    "                            end_date=ENDDATE,\n",
    "                            strategy_yaml_file=f'{LLM_PROMPTS_PATH}/strat_prompt_{PROMPT_VERSION}.yml')\n",
    "    execute_strategy_evaluation(role=\"llm\",\n",
    "                            ticker=TARGET,\n",
    "                            start_date=STARTDATE,\n",
    "                            end_date=ENDDATE,\n",
    "                            strategy_yaml_file=f'{LLM_PROMPTS_PATH}/strat_prompt_{PROMPT_VERSION}.yml')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5722911,
     "sourceId": 9421991,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 197612253,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "quant_drl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1234.187031,
   "end_time": "2024-09-17T20:07:16.406924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-17T19:46:42.219893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
