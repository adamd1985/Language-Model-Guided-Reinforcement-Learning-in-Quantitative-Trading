{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: LLM+RL Testbench for Risk Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we run our hybrid-architecture test bench."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-21T20:06:41.270Z",
     "iopub.execute_input": "2024-12-21T19:24:34.705394Z",
     "iopub.status.busy": "2024-12-21T19:24:34.705079Z",
     "iopub.status.idle": "2024-12-21T19:24:50.489103Z"
    },
    "papermill": {
     "duration": 0.761376,
     "end_time": "2024-09-17T19:46:45.797391",
     "exception": false,
     "start_time": "2024-09-17T19:46:45.036015",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext dotenv\n",
    "\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\", '/fundamentals')\n",
    "LLM_PROMPTS_PATH = os.getenv(\"LLM_PROMPTS_PATH\", '/prompts')\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\", '/fundamentals')\n",
    "HISTORIC_PATH = os.getenv(\"HISTORIC_PATH\", '/historic')\n",
    "MACRO_PATH = os.getenv(\"MACRO_PATH\", '/macro')\n",
    "OPTIONS_PATH = os.getenv(\"OPTIONS_PATH\", '/options')\n",
    "RL_OUTPUT_PATH = os.getenv(\"RL_OUTPUT_PATH\", '/rl_data')\n",
    "LLM_OUTPUT_PATH = os.getenv(\"LLM_OUTPUT_PATH\", '/llm_data')\n",
    "LOGS_PATH = os.getenv(\"LOGS_PATH\", '/logs')\n",
    "paths = [LLM_OUTPUT_PATH, LOGS_PATH, 'images']\n",
    "for path in paths:\n",
    "    if path and not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "DATA_PATH = './data'\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), 'utils'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import OpenAI\n",
    "from rl_agent_utils import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-21T20:06:41.271Z",
     "iopub.execute_input": "2024-12-21T19:24:50.509054Z",
     "iopub.status.busy": "2024-12-21T19:24:50.508472Z",
     "iopub.status.idle": "2024-12-21T19:24:50.517264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Environmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-21T20:06:41.272Z",
     "iopub.execute_input": "2024-12-21T19:24:50.539626Z",
     "iopub.status.busy": "2024-12-21T19:24:50.539409Z",
     "iopub.status.idle": "2024-12-21T19:24:50.554116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "money=100_000.\n",
    "stateLength = 30\n",
    "actionSpace = 2\n",
    "bounds = [1, 30]\n",
    "step = 1\n",
    "numberOfEpisodes = 50\n",
    "percentageCosts = [0, 0.1, 0.2]\n",
    "transactionCosts = percentageCosts[1]/100\n",
    "simulator = TradingSimulator()\n",
    "\n",
    "STARTDATE = '2012-01-01'\n",
    "SPLITDATE = '2018-01-01'\n",
    "ENDDATE = '2020-01-01'\n",
    "N_EXPERIMENTS = 10\n",
    "STOCKS = {\n",
    "    'Tesla' : 'TSLA',\n",
    "    'Apple' : 'AAPL',\n",
    "    'Facebook' : 'META',\n",
    "    'Amazon' : 'AMZN',\n",
    "    'Google' : 'GOOGL',\n",
    "    'Microsoft' : 'MSFT',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2024-12-21T20:06:41.272Z",
     "iopub.execute_input": "2024-12-21T19:24:50.554704Z",
     "iopub.status.busy": "2024-12-21T19:24:50.554527Z",
     "iopub.status.idle": "2024-12-21T19:26:46.874705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "STOCK_RESULTS = {}\n",
    "for stock_name, stock in tqdm(STOCKS.items(), disable=False, desc=\"Running work Bench...\"):\n",
    "    rl_output_dir = f'{RL_OUTPUT_PATH}/response/{RISK_EXPERIMENT}/{PROMPT_VERSION}'\n",
    "    os.makedirs(rl_output_dir, exist_ok=True)\n",
    "\n",
    "    train_file = f'{rl_output_dir}/{stock}_train_results.pkl'\n",
    "    test_file = f'{rl_output_dir}/{stock}_test_results.pkl'\n",
    "    sharpe_train_file = f'{rl_output_dir}/{stock}_sharpe_train_results.pkl'\n",
    "    sharpe_test_file = f'{rl_output_dir}/{stock}_sharpe_test_results.pkl'\n",
    "    time_file = f'{rl_output_dir}/{stock}_time_results.pkl'\n",
    "    q_train_file = f'{rl_output_dir}/{stock}_q_train.pkl'\n",
    "    q_test_file = f'{rl_output_dir}/{stock}_q_test.pkl'\n",
    "\n",
    "    input_file = f\"{HISTORIC_PATH}/engineered_{stock}_data.parquet\"\n",
    "    engineered_df = pd.read_parquet(input_file)\n",
    "    engineered_df.set_index('Date', inplace=True)\n",
    "    output_dir = f'{LLM_OUTPUT_PATH}/response/{RISK_EXPERIMENT}/{PROMPT_VERSION}'\n",
    "    engineered_df = generate_strategy_for_ticker(\n",
    "        ticker_df=engineered_df,\n",
    "        ticker=stock,\n",
    "        LLM_OUTPUT_PATH=output_dir,\n",
    "        persona=PERSONA,\n",
    "        HIGH_RISK_PROFILE=HIGH_RISK_PROFILE if RISK_EXPERIMENT == 'r' else LOW_RISK_PROFILE,\n",
    "        HIGH_OBJECTIVES=HIGH_OBJECTIVES if RISK_EXPERIMENT == 'r' else LOW_OBJECTIVES,\n",
    "        client=OPENAI_CLIENT,\n",
    "        model=OPENAI_MODEL,\n",
    "        strategy_yaml_file=f'{LLM_PROMPTS_PATH}/strat_prompt_{PROMPT_VERSION}.yml',\n",
    "        news_yaml_file=f'{LLM_PROMPTS_PATH}/analyst_prompt_v1.yml' if PROMPT_VERSION in ['v4'] else None,\n",
    "        start_date=STARTDATE,\n",
    "        end_date=ENDDATE,\n",
    "        max_news=5,\n",
    "        time_horizon='monthly',\n",
    "    )\n",
    "\n",
    "    if all(os.path.exists(f) for f in [train_file, test_file, time_file, q_train_file, q_test_file]):\n",
    "        with open(train_file, 'rb') as f:\n",
    "            train_results = pickle.load(f)\n",
    "        with open(test_file, 'rb') as f:\n",
    "            test_results = pickle.load(f)\n",
    "        with open(time_file, 'rb') as f:\n",
    "            time_results = pickle.load(f)\n",
    "        with open(q_train_file, 'rb') as f:\n",
    "            q_train_values = pickle.load(f)\n",
    "        with open(q_test_file, 'rb') as f:\n",
    "            q_test_values = pickle.load(f)\n",
    "        STOCK_RESULTS[stock] = (train_results, test_results, time_results, q_train_values, q_test_values)\n",
    "        continue\n",
    "\n",
    "    train_results = []\n",
    "    test_results = []\n",
    "    sharpe_train_results = []\n",
    "    sharpe_test_results = []\n",
    "    train_times = []\n",
    "    test_times = []\n",
    "\n",
    "    for i in tqdm(range(N_EXPERIMENTS), desc=f\"Running test episodes for {stock}...\", disable=False, leave=False):\n",
    "        start_train_time = time.time()\n",
    "        strat, train_env, qt0, qt1, test_env, q0, q1 = simulator.simulateNewStrategy(\n",
    "            stock_df=engineered_df.copy(),\n",
    "            startingDate=STARTDATE,\n",
    "            endingDate=ENDDATE,\n",
    "            splitingDate=SPLITDATE,\n",
    "            verbose=True,\n",
    "            plotTraining=False,\n",
    "            rendering=False,\n",
    "            showPerformance=False,\n",
    "            saveStrategy=False,\n",
    "            money=money,\n",
    "            observationSpace=observationSpace,\n",
    "            actionSpace=actionSpace,\n",
    "            stateLength=stateLength,\n",
    "            bounds=bounds,\n",
    "            step=step,\n",
    "            numberOfEpisodes=numberOfEpisodes,\n",
    "            transactionCosts=transactionCosts,\n",
    "            ticker_symbol=stock,\n",
    "        )\n",
    "        end_train_time = time.time()\n",
    "        train_times.append(end_train_time - start_train_time)\n",
    "\n",
    "        analyser = PerformanceEstimator(train_env.data)\n",
    "        train_perf = analyser.getComputedPerformance()\n",
    "        sharpe_perf = analyser.computeSharpeRatio()\n",
    "        sharpe_train_results.append(sharpe_perf)\n",
    "        train_results.append(train_perf)\n",
    "\n",
    "        start_test_time = time.time()\n",
    "        analyser = PerformanceEstimator(test_env.data)\n",
    "        test_perf = analyser.getComputedPerformance()\n",
    "        sharpe_perf = analyser.computeSharpeRatio()\n",
    "        sharpe_test_results.append(sharpe_perf)\n",
    "        test_results.append(test_perf)\n",
    "        end_test_time = time.time()\n",
    "        test_times.append(end_test_time - start_test_time)\n",
    "\n",
    "    avg_train_time = sum(train_times) / N_EXPERIMENTS\n",
    "    avg_test_time = sum(test_times) / N_EXPERIMENTS\n",
    "    time_results = {\n",
    "        'avg_train_time': avg_train_time,\n",
    "        'avg_test_time': avg_test_time\n",
    "    }\n",
    "    q_train_values = (qt0, qt1)\n",
    "    q_test_values = (q0, q1)\n",
    "    STOCK_RESULTS[stock] = (train_results, test_results, time_results, q_train_values, q_test_values)\n",
    "\n",
    "    with open(train_file, 'wb') as f:\n",
    "        pickle.dump(train_results, f)\n",
    "    with open(test_file, 'wb') as f:\n",
    "        pickle.dump(test_results, f)\n",
    "    with open(sharpe_train_file, 'wb') as f:\n",
    "        pickle.dump(sharpe_train_results, f)\n",
    "    with open(sharpe_test_file, 'wb') as f:\n",
    "        pickle.dump(sharpe_test_results, f)\n",
    "    with open(time_file, 'wb') as f:\n",
    "        pickle.dump(time_results, f)\n",
    "    with open(q_train_file, 'wb') as f:\n",
    "        pickle.dump(q_train_values, f)\n",
    "    with open(q_test_file, 'wb') as f:\n",
    "        pickle.dump(q_test_values, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Results and T-Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T21:45:43.627542Z",
     "iopub.status.busy": "2024-12-21T21:45:43.627339Z",
     "iopub.status.idle": "2024-12-21T21:45:44.390100Z",
     "shell.execute_reply": "2024-12-21T21:45:44.388679Z",
     "shell.execute_reply.started": "2024-12-21T21:45:43.627522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "final_summary_df = pd.DataFrame()\n",
    "rl_output_dir = f'{RL_OUTPUT_PATH}/response/{RISK_EXPERIMENT}/{PROMPT_VERSION}'\n",
    "replication_dir = \"./papers/bm_experiment\"\n",
    "\n",
    "for stock_name, stock in tqdm(STOCKS.items(), disable=False, desc=\"Testing stock workbench...\"):\n",
    "\n",
    "    f = f'{rl_output_dir}/{stock}_test_results.pkl'\n",
    "    new_results = safe_pickle_load(f)\n",
    "    f = f'{replication_dir}/{stock}_bm_test_results.pkl'\n",
    "    baseline_results = safe_pickle_load(f)\n",
    "    f = f'{rl_output_dir}/{stock}_time_results.pkl'\n",
    "    time_results = safe_pickle_load(f)\n",
    "\n",
    "    metrics_data = {}\n",
    "\n",
    "    for new_df, base_df in zip(new_results, baseline_results):\n",
    "        new_metrics = new_df.set_index(\"Metric\")[\"Value\"].to_dict()\n",
    "        base_metrics = base_df.set_index(\"Metric\")[\"Value\"].to_dict()\n",
    "\n",
    "        for metric in new_metrics:\n",
    "            if metric not in base_metrics:\n",
    "                continue\n",
    "            if metric not in metrics_data:\n",
    "                metrics_data[metric] = {'new': [], 'base': []}\n",
    "            metrics_data[metric]['new'].append(new_metrics[metric])\n",
    "            metrics_data[metric]['base'].append(base_metrics[metric])\n",
    "\n",
    "    stock_summary = {}\n",
    "    for metric, sets in metrics_data.items():\n",
    "        new_data = pd.Series(sets['new']).fillna(0)\n",
    "        base_data = pd.Series(sets['base']).fillna(0)\n",
    "\n",
    "        mean_val = round(new_data.mean(), 2)\n",
    "        std_val = round(new_data.std(), 2)\n",
    "\n",
    "        if len(new_data) == len(base_data) and len(new_data) > 1:\n",
    "            t_stat, p_value = ttest_rel(new_data, base_data)\n",
    "            p_value = round(p_value, 2)\n",
    "        else:\n",
    "            p_value = 0\n",
    "\n",
    "        stock_summary[metric] = [mean_val, std_val, p_value]\n",
    "\n",
    "    stock_df = pd.DataFrame(stock_summary, index=[\"Mean\", \"+/-\", \"P-Value\"]).T\n",
    "    stock_df = stock_df.T.unstack().to_frame().T\n",
    "    stock_df.index = [stock]\n",
    "\n",
    "    stock_df['Avg Train Time (s)'] = time_results['avg_train_time']\n",
    "    stock_df['Avg Test Time (s)'] = time_results['avg_test_time']\n",
    "\n",
    "    final_summary_df = pd.concat([final_summary_df, stock_df])\n",
    "\n",
    "final_summary_df.to_csv('final_summary_vs_replication.csv', index=True)\n",
    "pprint(final_summary_df.T)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6350571,
     "sourceId": 10265097,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 214190607,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 214194979,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "quant_drl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1234.187031,
   "end_time": "2024-09-17T20:07:16.406924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-17T19:46:42.219893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
