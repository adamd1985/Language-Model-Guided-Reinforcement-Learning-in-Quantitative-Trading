{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - Prompt Refinement Loop with Write-Judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we run the Writer-Judge loop, we assume the baseline prompt was already constructed using the `writer_trainer_v1` prompt in the Baseline Prompt construction and EDA notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext dotenv\n",
    "\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\")\n",
    "LLM_PROMPTS_PATH = os.getenv(\"LLM_PROMPTS_PATH\")\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\")\n",
    "HISTORIC_PATH = os.getenv(\"HISTORIC_PATH\")\n",
    "MACRO_PATH = os.getenv(\"MACRO_PATH\")\n",
    "OPTIONS_PATH = os.getenv(\"OPTIONS_PATH\")\n",
    "LLM_OUTPUT_PATH = os.getenv(\"LLM_OUTPUT_PATH\")\n",
    "LOGS_PATH = os.getenv(\"LOGS_PATH\")\n",
    "paths = [LLM_OUTPUT_PATH, LOGS_PATH]\n",
    "for path in paths:\n",
    "    if path and not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:39:13.829574Z",
     "iopub.status.busy": "2024-09-23T14:39:13.829218Z",
     "iopub.status.idle": "2024-09-23T14:39:14.190909Z",
     "shell.execute_reply": "2024-09-23T14:39:14.189908Z",
     "shell.execute_reply.started": "2024-09-23T14:39:13.829533Z"
    },
    "papermill": {
     "duration": 0.761376,
     "end_time": "2024-09-17T19:46:45.797391",
     "exception": false,
     "start_time": "2024-09-17T19:46:45.036015",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), 'utils'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data_utils import *\n",
    "from rl_agent_utils import *\n",
    "\n",
    "\n",
    "def enum_to_str_representer(dumper, data):\n",
    "    \"\"\"Helper function to represent enums as their string values in YAML.\"\"\"\n",
    "    return dumper.represent_str(data.value)\n",
    "\n",
    "yaml.add_representer(Action, enum_to_str_representer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"META\"\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "START_DATE = '2012-01-01'\n",
    "SPLITDATE = '2018-01-01'\n",
    "END_DATE = '2020-01-01'\n",
    "RISK_EXPERIMENT = 'r'\n",
    "PROMPT_VERSION = 'v2'\n",
    "\n",
    "WRITER_PROMPT_YML = f'{LLM_PROMPTS_PATH}/writer_generator_v1.yml'\n",
    "JUDGE_PROMPT_YML = f'{LLM_PROMPTS_PATH}/judge_prompt_v1.yml'\n",
    "\n",
    "NUM_SAMPLES = 2\n",
    "SAMPLE_HORIZON = 30  # days\n",
    "WRITER_PROMPT_YML = f'{LLM_PROMPTS_PATH}/writer_generator_v1.yml'\n",
    "JUDGE_PROMPT_YML = f'{LLM_PROMPTS_PATH}/judge_prompt_v1.yml'\n",
    "\n",
    "OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"{HISTORIC_PATH}/engineered_{TARGET}_data.parquet\"\n",
    "stock_aug_data = pd.read_parquet(output_file)\n",
    "stock_aug_data['Date'] = pd.to_datetime(stock_aug_data['Date'], utc=True)\n",
    "stock_aug_data.set_index('Date', inplace=True)\n",
    "\n",
    "sample_start_date = pd.Timestamp(START_DATE, tz='UTC')\n",
    "sample_end_date = pd.Timestamp(END_DATE, tz='UTC')\n",
    "\n",
    "stock_aug_data = stock_aug_data.loc[sample_start_date:sample_end_date]\n",
    "stock_aug_data.tail(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writer Judge Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeResponse(BaseModel):\n",
    "    features: str\n",
    "    judge_critique: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_sample_dates(dataframe, num_samples=15):\n",
    "    timestamps = pd.to_datetime(dataframe.index, utc=True)\n",
    "    random_dates = np.random.choice(timestamps, size=num_samples, replace=False)\n",
    "    return pd.to_datetime(random_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Loop\n",
    "\n",
    "Using a cost effective LLM for writing and a rationale superior LLM for judging.\n",
    "Juding output will be used to distil the former LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_SEED = r\"\"\"\n",
    "  Last_Strategy_Used_Data:\n",
    "    Cumulative_Returns: \"{Last_LLM_Strat_Cum_Returns}\"\n",
    "    Peak_Returns: \"{Last_LLM_Strat_Best_Returns}\"\n",
    "    Worst_Losses: \"{Last_LLM_Strat_Worse_Returns}\"\n",
    "    Rationale: |\n",
    "       \"{Last_LLM_Strat}\"\n",
    "\n",
    "  Stock_Data:\n",
    "    General:\n",
    "      Beta: {Market_Beta}\n",
    "      Classification: {classification}\n",
    "\n",
    "    Last_Weeks_Price:\n",
    "      Close: \"{Close}\"\n",
    "      Volume: \"{Volume}\"\n",
    "\n",
    "    Weekly_Past_Returns: \"{Weekly_Past_Returns}\"\n",
    "\n",
    "    Historical_Volatility:\n",
    "      HV_Close: \"{HV_Close}\"\n",
    "\n",
    "    Implied_Volatility:\n",
    "      IV_Close: \"{IV_Close}\"\n",
    "\n",
    "  Fundamental_Data:\n",
    "    Ratios:\n",
    "      Current_Ratio: \"{Current_Ratio}\"\n",
    "      Quick_Ratio: \"{Quick_Ratio}\"\n",
    "      Debt_to_Equity_Ratio: \"{Debt_to_Equity_Ratio}\"\n",
    "      PE_Ratio: \"{PE_Ratio}\"\n",
    "    Margins:\n",
    "      Gross_Margin: \"{Gross_Margin}\"\n",
    "      Operating_Margin: \"{Operating_Margin}\"\n",
    "      Net_Profit_Margin: \"{Net_Profit_Margin}\"\n",
    "    Growth Metrics:\n",
    "      EPS_YoY: \"{EPS_YoY_Growth}\"\n",
    "      Net_Income_YoY: \"{Net_Income_YoY_Growth}\"\n",
    "      Free_Cash_Flow_YoY: \"{Free_Cash_Flow_Per_Share_YoY_Growth}\"\n",
    "\n",
    "  Technical_Analysis:\n",
    "    Moving_Averages:\n",
    "      20MA: \"{20MA}\"\n",
    "      50MA: \"{50MA}\"\n",
    "      200MA: \"{200MA}\"\n",
    "    MACD:\n",
    "      Value: \"{MACD}\"\n",
    "      Signal_Line: \"{Signal_Line}\"\n",
    "      MACD_Strength: {MACD_Strength}\n",
    "    RSI:\n",
    "      Value: \"{RSI}\"\n",
    "    ATR: \"{ATR}\"\n",
    "\n",
    "  Macro_Data:\n",
    "    Macro_Indices:\n",
    "      SPX:\n",
    "        Close: \"{SPX_Close}\"\n",
    "        Close_20MA: \"{SPX_Close_MA}\"\n",
    "        Close_Slope: \"{SPX_Close_Slope}\"\n",
    "      VIX:\n",
    "        Close: \"{VIX_Close}\"\n",
    "        Close_20MA: \"{VIX_Close_MA}\"\n",
    "        Close_Slope: \"{VIX_Close_Slope}\"\n",
    "    Economic_Data:\n",
    "      GDP_QoQ: \"{GDP_QoQ}\"\n",
    "      PMI: \"{PMI}\"\n",
    "      Consumer_Confidence_QoQ: \"{Consumer_Confidence_QoQ}\"\n",
    "      M2_Money_Supply_QoQ: \"{M2_Money_Supply_QoQ}\"\n",
    "      PPI_YoY: \"{PPI_YoY}\"\n",
    "      Treasury_Yields_YoY: \"{Treasury_Yields_YoY}\"\n",
    "\n",
    "  Options_Data:\n",
    "    Put_IV_Skews:\n",
    "      OTM_Skew: \"{OTM_Skew}\"\n",
    "      ATM_Skew: \"{ATM_Skew}\"\n",
    "      ITM_Skew: \"{ITM_Skew}\"\n",
    "    20Day_Moving_Averages:\n",
    "      OTM_Skew_MA: \"{MA_OTM_Skew}\"\n",
    "      ATM_Skew_MA: \"{MA_ATM_Skew}\"\n",
    "      ITM_Skew_MA: \"{MA_ITM_Skew}\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS_SEED = r\"\"\"\n",
    "persona: {persona}\n",
    "risk_profile: {risk_profile}\n",
    "portfolio_objectives: {portfolio_objectives}\n",
    "instructions: |\n",
    "  Develop a trading strategy for the next month based on the given context and aligned with the specified `portfolio_objectives` and `risk_profile`. Use the following process:\n",
    "\n",
    "  1. Comprehensive Data Analysis:\n",
    "     - Stock Data: Examine price trends, volume, and HV/IV metrics for momentum or risk signals.\n",
    "     - Fundamental Data: Focus on profitability margins and ratios based on risk tolerance.\n",
    "     - Technical Analysis: Use RSI for overbought/oversold conditions, MAs for trend confirmation, and MACD for momentum analysis.\n",
    "     - Macro Data: Evaluate GDP, PMI, and VIX trends to assess broader sentiment.\n",
    "     - Options Data: Prioritize implied volatility metrics to capture sentiment shifts.\n",
    "     - Dynamic Feature Weighting by Risk Profile:\n",
    "      - High-Risk Profile:\n",
    "        - Prioritize volatility and momentum indicators such as RSI, MACD, ATR, and Options_Data.ATM_IV.Call.\n",
    "        - Weigh macroeconomic indicators (e.g., VIX, GDP_QoQ) for risk-on sentiment.\n",
    "      - Low-Risk Profile:\n",
    "        - Focus on stability metrics like Debt-to-Equity Ratio, Operating Margin, and Current Ratio.\n",
    "        - Analyze implied volatility skews (Options_Data.ITM_Skew) for downside risk mitigation.\n",
    "        - Use macroeconomic stability indicators such as Consumer Confidence QoQ and Treasury Yields.\n",
    "\n",
    "  2. Reflection and Iterative Learning:\n",
    "      - If not None, evaluate `Last_Strategy_Used_Data` for performance gaps and reflect on your chosen `action`.\n",
    "      - If not None, use CoT reasoning to adjust mismatches between past assumptions and actual market behavior.\n",
    "      - Weigh the feature importance in your rationale using a Likert scale of 3:\n",
    "        - level: 1\n",
    "          description: The feature has minimal relevance or impact; it is not necessary and can be ignored.\n",
    "        - level: 2\n",
    "          description: The feature has some relevance and contributes to the strategy but is not crucial.\n",
    "        - level: 3\n",
    "          description: The feature is important and significantly contributes to achieving a successful strategy.\n",
    "\n",
    "Output:\n",
    "  action: str. LONG or SHORT.\n",
    "  explanation: >\n",
    "    A clear, concise rationale (max 350 words) including the top 5 weighted features with the news as a factor used in decision-making (ICL Example: \"Stock_Data.Price.Close, Weight 3, Technical_Analysis.RSI.Value, Weight 1, Options_Data.ATM_IV.Call, Weight 2\"), and if `news_factors` was provided, the top 3 ranked news factors, weighted the same using the Likert scale (ICL Example: \"Earning Call next month, with positive analyst expectations, Weight 3.\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import yaml\n",
    "from jinja2 import Template\n",
    "\n",
    "def flatten_yaml_keys(d, parent_key='', sep='.'):\n",
    "    items = {}\n",
    "    for k, v in d.items():\n",
    "        key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.update(flatten_yaml_keys(v, key, sep=sep))\n",
    "        else:\n",
    "            items[key] = v\n",
    "    return items\n",
    "\n",
    "\n",
    "def fill_yaml_template(context, template_path):\n",
    "    with open(template_path, \"r\") as f:\n",
    "        raw_template = f.read()\n",
    "    return Template(raw_template).render(**context)\n",
    "\n",
    "\n",
    "def call_writer(strategy_context, template_path, model, client):\n",
    "    prompt_filled = fill_yaml_template(strategy_context, template_path)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_filled}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=2300,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def call_judge(train_template, template_path, model, client, distil=False):\n",
    "    context = {'train_template': train_template, 'shared_memory': \"\"}\n",
    "    prompt_filled = fill_yaml_template(context, template_path)\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_filled}],\n",
    "        temperature=0.7,\n",
    "        store=distil,\n",
    "        response_format=JudgeResponse,\n",
    "        max_tokens=2300,\n",
    "    )\n",
    "    parsed = response.choices[0].message.parsed\n",
    "    return {\"Selected Features\": parsed.features, \"strategy Rationale\": parsed.judge_critique}\n",
    "\n",
    "\n",
    "def backtest_strategy_from_llm(instructions, data_slice, client, model, features_input=None):\n",
    "    if data_slice.shape[0] < 2 or 'Close' not in data_slice.columns:\n",
    "        return np.nan\n",
    "    messages = [{\"role\": \"user\", \"content\": instructions}]\n",
    "    if features_input:\n",
    "        messages.append({\"role\": \"user\", \"content\": features_input})\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.0,\n",
    "            max_tokens=800,\n",
    "        )\n",
    "        llm_reply = response.choices[0].message.content.strip().upper()\n",
    "    except Exception as e:\n",
    "        print(f\"[!] LLM call failed: {e}\")\n",
    "        return np.nan\n",
    "    if \"SHORT\" in llm_reply:\n",
    "        direction = \"SHORT\"\n",
    "    elif \"LONG\" in llm_reply:\n",
    "        direction = \"LONG\"\n",
    "    else:\n",
    "        return np.nan\n",
    "    start_price = data_slice['Close'].iloc[0]\n",
    "    end_price = data_slice['Close'].iloc[-1]\n",
    "    return (end_price - start_price) / start_price if direction == \"LONG\" else (start_price - end_price) / start_price\n",
    "\n",
    "\n",
    "def run_iterative_writer_judge_loop(\n",
    "    stock_data,\n",
    "    sampled_dates,\n",
    "    writer_prompt_path,\n",
    "    judge_prompt_path,\n",
    "    risk_profile,\n",
    "    portfolio_objectives,\n",
    "    model,\n",
    "    client,\n",
    "    features_seed_yaml,\n",
    "    sample_horizon=30,\n",
    "    distil=False,\n",
    "    regret_threshold=0.01,\n",
    "    max_iterations=3\n",
    "):\n",
    "    results = []\n",
    "    features_seed_dict = yaml.safe_load(features_seed_yaml)\n",
    "    features_reranked_dict = {k: 2 for k in flatten_yaml_keys(features_seed_dict)}\n",
    "\n",
    "    for dt in sampled_dates:\n",
    "        try:\n",
    "            start_dt = pd.to_datetime(dt)\n",
    "            end_dt = start_dt + timedelta(days=sample_horizon)\n",
    "            sliced_data = stock_data.loc[start_dt:end_dt]\n",
    "            previous_critiques = \"\"\n",
    "            regret = float(\"inf\")\n",
    "            iteration = 0\n",
    "            best_return = -np.inf\n",
    "            best_instruction = None\n",
    "            best_features = None\n",
    "            best_critique = None\n",
    "\n",
    "            while regret > regret_threshold and iteration < max_iterations:\n",
    "                context = {\n",
    "                    'Features_Reranked': features_reranked_dict,\n",
    "                    'judge_critique': previous_critiques if previous_critiques else \"\",\n",
    "                    'risk_profile': risk_profile,\n",
    "                    'portfolio_objectives': portfolio_objectives\n",
    "                }\n",
    "\n",
    "                instructions = call_writer(context, writer_prompt_path, model, client)\n",
    "                realized_return = backtest_strategy_from_llm(\n",
    "                    instructions=instructions,\n",
    "                    data_slice=sliced_data,\n",
    "                    client=client,\n",
    "                    model=model,\n",
    "                    features_input=features_seed_yaml\n",
    "                )\n",
    "\n",
    "                if not np.isnan(realized_return) and realized_return > best_return:\n",
    "                    best_return = realized_return\n",
    "                    best_instruction = instructions\n",
    "\n",
    "                regret = abs(0.0 - realized_return)\n",
    "                if regret <= regret_threshold:\n",
    "                    break\n",
    "\n",
    "                judge_feedback = call_judge(instructions, judge_prompt_path, model, client, distil)\n",
    "                previous_critiques += \"\\n\" + judge_feedback[\"strategy Rationale\"]\n",
    "                best_features = judge_feedback[\"Selected Features\"]\n",
    "                best_critique = judge_feedback[\"strategy Rationale\"]\n",
    "                iteration += 1\n",
    "\n",
    "            results.append({\n",
    "                'sample_start': start_dt,\n",
    "                'sample_end': end_dt,\n",
    "                'strategy_text': best_instruction,\n",
    "                'selected_features': best_features,\n",
    "                'judge_explanation': best_critique,\n",
    "                'return': best_return,\n",
    "                'regret': regret,\n",
    "                'iterations': iteration\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[!] Error processing date {dt}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dates = generate_random_sample_dates(stock_aug_data, NUM_SAMPLES)\n",
    "\n",
    "final_df = run_iterative_writer_judge_loop(\n",
    "    stock_data=stock_aug_data,\n",
    "    sampled_dates=sampled_dates,\n",
    "    writer_prompt_path=WRITER_PROMPT_YML,\n",
    "    judge_prompt_path=JUDGE_PROMPT_YML,\n",
    "    risk_profile=HIGH_RISK_PROFILE,\n",
    "    portfolio_objectives=HIGH_OBJECTIVES,\n",
    "    model=OPENAI_MODEL,\n",
    "    client=OPENAI_CLIENT,\n",
    "    features_seed_yaml=FEATURES_SEED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(1)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5722911,
     "sourceId": 9421991,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 197612253,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "quant_drl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1234.187031,
   "end_time": "2024-09-17T20:07:16.406924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-17T19:46:42.219893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
