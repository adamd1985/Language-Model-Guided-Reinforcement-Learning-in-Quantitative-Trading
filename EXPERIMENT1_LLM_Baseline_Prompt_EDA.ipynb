{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment - Baseline Prompt with Exemplars and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes the exemplar trades and attempts to explain the causal actions of the expert. Additionally we do a prompt EDA, to see what the LLM is focusing on.\n",
    "\n",
    "For the Writer-Judge setup, refer to the Writer-Judge notebook. Writer judge is used to finetune the selected features and instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "INSTALL_DEPS = False\n",
    "if INSTALL_DEPS:\n",
    "    %pip install openai==1.51.2\n",
    "\n",
    "%load_ext dotenv\n",
    "\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\")\n",
    "LLM_PROMPTS_PATH = os.getenv(\"LLM_PROMPTS_PATH\")\n",
    "FUNDAMENTALS_PATH = os.getenv(\"FUNDAMENTALS_PATH\")\n",
    "HISTORIC_PATH = os.getenv(\"HISTORIC_PATH\")\n",
    "MACRO_PATH = os.getenv(\"MACRO_PATH\")\n",
    "OPTIONS_PATH = os.getenv(\"OPTIONS_PATH\")\n",
    "LLM_OUTPUT_PATH = os.getenv(\"LLM_OUTPUT_PATH\")\n",
    "LOGS_PATH = os.getenv(\"LOGS_PATH\")\n",
    "paths = [LLM_OUTPUT_PATH, LOGS_PATH]\n",
    "for path in paths:\n",
    "    if path and not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n",
    "    logging.info(\"Running in Kaggle...\")\n",
    "    for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "    DATA_PATH = \"/kaggle/input/drl-dataset-quant\"\n",
    "    FUNDAMENTALS_PATH = DATA_PATH + FUNDAMENTALS_PATH\n",
    "    HISTORIC_PATH = DATA_PATH + HISTORIC_PATH\n",
    "    MACRO_PATH = DATA_PATH + MACRO_PATH\n",
    "    OPTIONS_PATH = DATA_PATH + OPTIONS_PATH\n",
    "\n",
    "    sys.path.insert(1, \"/kaggle/usr/lib/drlutil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:39:13.829574Z",
     "iopub.status.busy": "2024-09-23T14:39:13.829218Z",
     "iopub.status.idle": "2024-09-23T14:39:14.190909Z",
     "shell.execute_reply": "2024-09-23T14:39:14.189908Z",
     "shell.execute_reply.started": "2024-09-23T14:39:13.829533Z"
    },
    "papermill": {
     "duration": 0.761376,
     "end_time": "2024-09-17T19:46:45.797391",
     "exception": false,
     "start_time": "2024-09-17T19:46:45.036015",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), 'utils'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data_utils import *\n",
    "from rl_agent_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '20120101'\n",
    "END_DATE = '20200101'\n",
    "TARGET = \"AAPL\"\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\") # Best use a more rationale model like 4o or 1o.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"{HISTORIC_PATH}/engineered_{TARGET}_data.parquet\"\n",
    "stock_aug_data = pd.read_parquet(output_file)\n",
    "stock_aug_data.set_index('Date', inplace=True)\n",
    "stock_aug_data.tail(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_df = expert_trades(stock_aug_data.copy())\n",
    "expert_df.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_start_date = pd.Timestamp(\"2019-05-01 00:00:00+02:00\")\n",
    "sample_end_date = pd.Timestamp(\"2019-07-30 00:00:00+02:00\")\n",
    "\n",
    "engineered_sample_df = stock_aug_data.loc[sample_start_date:sample_end_date]\n",
    "expert_sample_df = expert_df.loc[sample_start_date:sample_end_date]\n",
    "engineered_sample_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pickle\n",
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "from textwrap import dedent\n",
    "from typing import List\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def enum_to_str_representer(dumper, data):\n",
    "    \"\"\"Helper function to represent enums as their string values in YAML.\"\"\"\n",
    "    return dumper.represent_str(data.value)\n",
    "\n",
    "yaml.add_representer(Action, enum_to_str_representer)\n",
    "\n",
    "OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_EXPERIMENT = 'r'\n",
    "TRAIN_PROMPT_YML = f'{LLM_PROMPTS_PATH}/writer_trainer_v1.yml'\n",
    "\n",
    "TICKERS = [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\", \"AMZN\", \"META\"]\n",
    "PROMPT_SAMPLES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class ExpertReview(BaseModel):\n",
    "    explanation: str\n",
    "    features: List[str]\n",
    "\n",
    "class ReflectTradeStrategy(BaseModel):\n",
    "    reflection: str\n",
    "    suggestions: List[str]\n",
    "    features: List[str]\n",
    "    explanation: str\n",
    "\n",
    "def train_trade_strategy(step, context, persona, client, model, response_format=ExpertReview, top_k_tokens=5, max_retries=2):\n",
    "    retries = 0\n",
    "    response_data = None\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.beta.chat.completions.parse(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": f\"Step: {step}\\nPrompt: {context}\\n\"}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                top_p=1,\n",
    "                top_logprobs=top_k_tokens,\n",
    "                response_format=response_format,\n",
    "                max_completion_tokens=3500,\n",
    "                frequency_penalty=1,\n",
    "                presence_penalty=0.25,\n",
    "                logprobs=True,\n",
    "            )\n",
    "\n",
    "            trade_strategy_response = response.choices[0].message\n",
    "            trade_strategy = trade_strategy_response.parsed if isinstance(trade_strategy_response.parsed, dict) else trade_strategy_response.parsed.__dict__\n",
    "\n",
    "            if trade_strategy is None:\n",
    "                raise Exception(\"trade_strategy None!\")\n",
    "\n",
    "            total_tokens = response.usage.total_tokens\n",
    "            prompt_tokens = response.usage.prompt_tokens\n",
    "            completion_tokens = response.usage.completion_tokens\n",
    "            cost = ((prompt_tokens / 1_000_000) * 0.15) + ((completion_tokens / 1_000_000) * 0.6)\n",
    "\n",
    "\n",
    "\n",
    "            token_logprobs = response.choices[0].logprobs.content\n",
    "            perplexity = calc_uncertainty_metrics(response.choices[0].logprobs.content)\n",
    "            long_token_proba = -float('inf')\n",
    "            short_token_proba = -float('inf')\n",
    "\n",
    "            for token_probs in token_logprobs:\n",
    "                if Action.LONG.value in token_probs.token:\n",
    "                    long_token_proba = token_probs.logprob\n",
    "                if Action.SHORT.value in token_probs.token:\n",
    "                    short_token_proba = token_probs.logprob\n",
    "\n",
    "            response_data = {\n",
    "                \"features\": trade_strategy['features'] if 'features' in trade_strategy else np.nan,\n",
    "                \"explanation\": trade_strategy['explanation'] if 'explanation' in trade_strategy else np.nan,\n",
    "                \"long_token_proba\": long_token_proba,\n",
    "                \"short_token_proba\": short_token_proba,\n",
    "                \"perplexity\": perplexity[\"perplexity\"],\n",
    "                \"entropy\": perplexity[\"entropy\"],\n",
    "                \"tokens_meta\": {\n",
    "                    \"total_tokens\": total_tokens,\n",
    "                    \"prompt_tokens\": prompt_tokens,\n",
    "                    \"completion_tokens\": completion_tokens,\n",
    "                    \"cost\": cost\n",
    "                },\n",
    "            }\n",
    "            return response_data  # Return once successful\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in LLM call: {e}\")\n",
    "            retries += 1\n",
    "            logging.info(f\"Retrying LLM call ({retries}/{max_retries})...\")\n",
    "\n",
    "    if response_data is None:\n",
    "        raise Exception(f\"None strategy encountered after {max_retries} retries\")\n",
    "\n",
    "    return response_data\n",
    "\n",
    "context = update_historical_data_context(engineered_sample_df.head(1),\n",
    "                                         PERSONA,\n",
    "                                         HIGH_RISK_PROFILE,\n",
    "                                         HIGH_OBJECTIVES,\n",
    "                                         expert_df=expert_sample_df)\n",
    "\n",
    "\n",
    "train_template = load_yaml_template(TRAIN_PROMPT_YML)\n",
    "filled_template = fill_yaml_template(context, train_template)\n",
    "context_yaml = yaml.dump(filled_template, default_flow_style=True, allow_unicode=True)\n",
    "\n",
    "trade_strategy = train_trade_strategy(1, context_yaml, PERSONA, OPENAI_CLIENT, OPENAI_MODEL)\n",
    "\n",
    "pprint(trade_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trade_prompt(engineered_df,\n",
    "                            anchor_date,\n",
    "                            risk_profile,\n",
    "                            objectives,\n",
    "                            persona,\n",
    "                            client, model,\n",
    "                            prev_trade_decision = None,\n",
    "                            prev_trade_returns = None,\n",
    "                            prev_trade_days = None,\n",
    "                            yaml_file = TRAIN_PROMPT_YML,\n",
    "                            Peak_Returns=None,\n",
    "                            Trough_Returns=None,\n",
    "                            expert_df=None):\n",
    "    train_template = load_yaml_template(yaml_file)\n",
    "    sample_engineered_df = engineered_df.loc[anchor_date - pd.Timedelta(days=1):anchor_date]\n",
    "    if sample_engineered_df.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    # Update context with historical data\n",
    "    context = update_historical_data_context(\n",
    "        engineered_df=sample_engineered_df.head(1),\n",
    "        persona=PERSONA,\n",
    "        HIGH_RISK_PROFILE=risk_profile,\n",
    "        HIGH_OBJECTIVES=objectives,\n",
    "        Last_LLM_Strat=prev_trade_decision,\n",
    "        Last_LLM_Strat_Returns=prev_trade_returns,\n",
    "        Last_LLM_Strat_Days = prev_trade_days,\n",
    "        Peak_Returns=Peak_Returns,\n",
    "        Trough_Returns=Trough_Returns,\n",
    "        expert_df=expert_df,\n",
    "    )\n",
    "    filled_template = fill_yaml_template(context, train_template)\n",
    "    context_yaml = yaml.dump(filled_template, default_flow_style=True, allow_unicode=True)\n",
    "\n",
    "    trade_strategy_response = train_trade_strategy(1, context_yaml, persona, client, model)\n",
    "    trade_strategy_response[\"trade_action\"] = 1 if context['Expert_Action'] == \"Long\" else 0\n",
    "\n",
    "    return trade_strategy_response\n",
    "\n",
    "strategy = generate_trade_prompt(engineered_df=engineered_sample_df,\n",
    "                                anchor_date=pd.to_datetime(\"20190612\", utc=True),\n",
    "                                risk_profile=HIGH_RISK_PROFILE,\n",
    "                                objectives=HIGH_OBJECTIVES,\n",
    "                                persona=PERSONA,\n",
    "                                client=OPENAI_CLIENT,\n",
    "                                model=OPENAI_MODEL,\n",
    "                                expert_df=expert_sample_df)\n",
    "pprint(strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_trades(engineered_df, risk_profile, objectives, persona, client, model, prompt_frequency='Monthly', expert_df=None):\n",
    "    if prompt_frequency not in ['Weekly', 'Monthly']:\n",
    "        raise ValueError(\"Invalid prompt_frequency. Choose 'Weekly' or 'Monthly'.\")\n",
    "\n",
    "    columns_to_fill = [\n",
    "        'strategy', 'strategy_probas', 'explanation',\n",
    "        'long_conf_score', 'short_conf_score', 'long_token_proba', 'short_token_proba',\n",
    "        'long_token_proba', 'short_token_proba', 'perplexity', 'news_factors',\n",
    "        'tokens_meta_strat', 'tokens_meta_news', 'tokens_meta_proba', 'entropy'\n",
    "    ]\n",
    "    engineered_df[columns_to_fill] = np.nan\n",
    "    previous_year = None\n",
    "    previous_month = None\n",
    "    previous_week = None\n",
    "    for date, row in tqdm(engineered_df.iterrows(), desc=\"Generating strategies...\"):\n",
    "        trigger_prompt = False\n",
    "\n",
    "        if prompt_frequency == 'Monthly':\n",
    "            if previous_month != date.month or previous_year != date.year:\n",
    "                current_month_start = date.replace(day=1)\n",
    "                current_month_first_business_day = pd.date_range(current_month_start, periods=1, freq='B')[0]\n",
    "                if date == current_month_first_business_day:\n",
    "                    trigger_prompt = True\n",
    "                    previous_month = date.month\n",
    "                    previous_year = date.year\n",
    "\n",
    "        elif prompt_frequency == 'Weekly':\n",
    "            if previous_week != date.isocalendar()[1] or previous_year != date.year:\n",
    "                current_week_start = date.to_period('W').start_time\n",
    "                current_week_first_business_day = pd.date_range(current_week_start, periods=1, freq='B')[0]\n",
    "                if date == current_week_first_business_day:\n",
    "                    trigger_prompt = True\n",
    "                    previous_week = date.isocalendar()[1]\n",
    "                    previous_year = date.year\n",
    "\n",
    "        if trigger_prompt:\n",
    "\n",
    "            start_idx = engineered_df.index.get_indexer([date], method='nearest')[0]\n",
    "            prev_row = engineered_df.iloc[start_idx]\n",
    "\n",
    "            trade_decision = generate_trade_prompt(\n",
    "                engineered_df=engineered_df,\n",
    "                anchor_date=date,\n",
    "                risk_profile=risk_profile,\n",
    "                objectives=objectives,\n",
    "                persona=persona,\n",
    "                client=client,\n",
    "                model=model,\n",
    "                prev_trade_decision=None,\n",
    "                prev_trade_returns=None,\n",
    "                prev_trade_days=None,\n",
    "                Peak_Returns=None,\n",
    "                Trough_Returns=None,\n",
    "                expert_df=expert_df\n",
    "            )\n",
    "\n",
    "            if not trade_decision:\n",
    "                continue\n",
    "            engineered_df.loc[date:, 'trade_action'] = trade_decision['trade_action']\n",
    "            engineered_df.loc[date:, 'evaluation_iteration'] = 1\n",
    "            engineered_df.loc[date:, 'evaluation_score'] = None\n",
    "            engineered_df.loc[date:, 'acceptance_rate'] = 1\n",
    "            engineered_df.loc[date:, 'features'] = ','.join(trade_decision['features'])\n",
    "            engineered_df.loc[date:, 'explanation'] = trade_decision['explanation']\n",
    "            engineered_df.loc[date:, 'perplexity'] = trade_decision['perplexity']\n",
    "            engineered_df.loc[date:, 'entropy'] = trade_decision['entropy']\n",
    "            engineered_df.loc[date:, 'long_token_proba'] = trade_decision['long_token_proba']\n",
    "            engineered_df.loc[date:, 'short_token_proba'] = trade_decision['short_token_proba']\n",
    "            engineered_df.loc[date:, 'tokens_meta_strat'] = pd.Series([trade_decision[\"tokens_meta\"]] * len(engineered_df.loc[date:]), index=engineered_df.loc[date:].index)\n",
    "\n",
    "\n",
    "    engineered_df[columns_to_fill].bfill(inplace=True)\n",
    "    engineered_df[columns_to_fill].ffill(inplace=True)\n",
    "\n",
    "    return engineered_df\n",
    "\n",
    "llm_decisions_df = llm_trades(\n",
    "    engineered_df=engineered_sample_df,\n",
    "    risk_profile=HIGH_RISK_PROFILE,\n",
    "    objectives=HIGH_OBJECTIVES,\n",
    "    persona=PERSONA,\n",
    "    client=OPENAI_CLIENT,\n",
    "    model=OPENAI_MODEL,\n",
    "    expert_df=expert_sample_df\n",
    ")\n",
    "\n",
    "llm_decisions_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(llm_decisions_df['explanation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_trading_metrics, llm_trades_df = evaluate_trading_metrics(llm_decisions_df)\n",
    "plot_llm_trade(llm_trades_df)\n",
    "\n",
    "llm_trading_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_start_date = pd.Timestamp(\"2019-01-01 00:00:00+01:00\")\n",
    "sample_end_date = pd.Timestamp(\"2019-03-01 00:00:00+01:00\")\n",
    "\n",
    "engineered_sample_df = stock_aug_data.loc[sample_start_date:sample_end_date]\n",
    "expert_sample_df = expert_df.loc[sample_start_date:sample_end_date]\n",
    "\n",
    "llm_decisions_df = llm_trades(\n",
    "    engineered_df=engineered_sample_df,\n",
    "    risk_profile=HIGH_RISK_PROFILE,\n",
    "    objectives=HIGH_OBJECTIVES,\n",
    "    persona=PERSONA,\n",
    "    client=OPENAI_CLIENT,\n",
    "    model=OPENAI_MODEL,\n",
    "    expert_df=expert_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(llm_decisions_df['explanation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_start_date = pd.Timestamp(\"2019-04-01 00:00:00+01:00\")\n",
    "sample_end_date = pd.Timestamp(\"2019-05-30 00:00:00+01:00\")\n",
    "\n",
    "engineered_sample_df = stock_aug_data.loc[sample_start_date:sample_end_date]\n",
    "expert_sample_df = expert_df.loc[sample_start_date:sample_end_date]\n",
    "\n",
    "llm_decisions_df = llm_trades(\n",
    "    engineered_df=engineered_sample_df,\n",
    "    risk_profile=HIGH_RISK_PROFILE,\n",
    "    objectives=HIGH_OBJECTIVES,\n",
    "    persona=PERSONA,\n",
    "    client=OPENAI_CLIENT,\n",
    "    model=OPENAI_MODEL,\n",
    "    expert_df=expert_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(llm_decisions_df['explanation'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_sample_dates(dataframe, num_samples=15):\n",
    "    timestamps = pd.to_datetime(dataframe.index, utc=True)\n",
    "    min_time, max_time = timestamps.min(), timestamps.max()\n",
    "    sample_dates = pd.date_range(start=min_time, end=max_time, periods=num_samples)\n",
    "    return sample_dates\n",
    "\n",
    "def generate_random_sample_dates(dataframe, num_samples=15):\n",
    "    timestamps = pd.to_datetime(dataframe.index, utc=True)\n",
    "    random_dates = np.random.choice(timestamps, size=num_samples, replace=False)\n",
    "    return pd.to_datetime(random_dates)\n",
    "\n",
    "def process_samples_for_ticker(\n",
    "    ticker, engineered_df, expert_df, risk_profile, objectives,\n",
    "    persona, client, model, num_samples=5, prompt_frequency='Monthly'\n",
    "):\n",
    "    sample_dates = generate_random_sample_dates(engineered_df, num_samples)\n",
    "    corpus = []\n",
    "\n",
    "    for anchor_date in tqdm(sample_dates, desc=f\"Processing {ticker}\", leave=False):\n",
    "        if prompt_frequency == 'Monthly':\n",
    "            start_date = anchor_date - pd.Timedelta(days=7)\n",
    "            end_date = anchor_date + pd.Timedelta(days=37)\n",
    "        elif prompt_frequency == 'Weekly':\n",
    "            start_date = anchor_date - pd.Timedelta(days=1)\n",
    "            end_date = anchor_date + pd.Timedelta(days=8)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid prompt_frequency. Choose 'Weekly' or 'Monthly'.\")\n",
    "\n",
    "        sliced_df = engineered_df.loc[start_date:end_date].copy()\n",
    "        if anchor_date not in sliced_df.index:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            trade_strategy = llm_trades(\n",
    "                engineered_df=sliced_df,\n",
    "                risk_profile=risk_profile,\n",
    "                objectives=objectives,\n",
    "                persona=persona,\n",
    "                client=client,\n",
    "                model=model,\n",
    "                prompt_frequency=prompt_frequency,\n",
    "                expert_df=expert_df\n",
    "            )\n",
    "            if trade_strategy is None:\n",
    "                continue\n",
    "            corpus.append({\n",
    "                \"ticker\": ticker,\n",
    "                \"anchor_date\": str(anchor_date),\n",
    "                \"context\": context_yaml,\n",
    "                \"explanation\": trade_strategy.iloc[-1]['explanation'],\n",
    "                \"features\": trade_strategy.iloc[-1]['features'],\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logging.error(e)\n",
    "\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def process_multiple_tickers(tickers,\n",
    "                                risk_profile,\n",
    "                                objectives,\n",
    "                                persona,\n",
    "                                client,\n",
    "                                model,\n",
    "                                num_samples=15,\n",
    "                                high_risk=True,\n",
    "                                startingDate=START_DATE,\n",
    "                                endingDate=END_DATE):\n",
    "    full_corpus = []\n",
    "    for ticker in tqdm(tickers):\n",
    "        print(f\"Processing Ticker: {ticker}\")\n",
    "\n",
    "        input_file = f\"{HISTORIC_PATH}/engineered_{ticker}_data.parquet\"\n",
    "        engineered_df = pd.read_parquet(input_file)\n",
    "        engineered_df.set_index('Date', inplace=True)\n",
    "        expert_df = expert_trades(stock_aug_data.copy(), high_risk=high_risk)\n",
    "\n",
    "        start_date = pd.to_datetime(startingDate, utc=True)\n",
    "        end_date = pd.to_datetime(endingDate, utc=True)\n",
    "        engineered_df = engineered_df.loc[start_date:end_date]\n",
    "        expert_df = expert_df.loc[start_date:end_date]\n",
    "\n",
    "        ticker_corpus = process_samples_for_ticker(\n",
    "            ticker=ticker,\n",
    "            engineered_df=engineered_df,\n",
    "            expert_df=expert_df,\n",
    "            risk_profile=risk_profile,\n",
    "            objectives=objectives,\n",
    "            persona=persona,\n",
    "            client=client,\n",
    "            model=model,\n",
    "            num_samples=num_samples\n",
    "        )\n",
    "        full_corpus.extend(ticker_corpus)\n",
    "    return full_corpus\n",
    "\n",
    "corpus_file = \"./risk_trade_strategy_corpus.yaml\"\n",
    "if os.path.exists(corpus_file):\n",
    "    print(f\"Corpus file '{corpus_file}' found. Reloading...\")\n",
    "    with open(corpus_file, \"r\") as f:\n",
    "        corpus = yaml.safe_load(f)\n",
    "else:\n",
    "    print(\"Corpus file not found. Generating new corpus...\")\n",
    "    OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    corpus = process_multiple_tickers(\n",
    "        tickers= TICKERS,\n",
    "        risk_profile=HIGH_RISK_PROFILE,\n",
    "        objectives=HIGH_OBJECTIVES,\n",
    "        persona=PERSONA,\n",
    "        client=OPENAI_CLIENT,\n",
    "        model=OPENAI_MODEL,\n",
    "        num_samples=PROMPT_SAMPLES,\n",
    "    )\n",
    "    with open(corpus_file, \"w\") as f:\n",
    "        yaml.dump(corpus, f, default_flow_style=False, allow_unicode=True, indent=2)\n",
    "    print(\"Corpus saved successfully.\")\n",
    "\n",
    "print(\"Corpus ready for use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Generation Through Writer-Judge\n",
    "\n",
    "\n",
    "### Exemplars Selection\n",
    "\n",
    "Need to finding the most similar explanations. Since we are using GPT-4 already, `text-embedding-3-small` or `text-embedding-ada-002` is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_corpus(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def get_or_compute_embeddings(explanations, client, model=\"text-embedding-3-small\", cache_path=\"embeddings_cache.pkl\"):\n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(explanations), 100), desc=\"Embedding\"):\n",
    "        batch = explanations[i:i+100]\n",
    "        response = client.embeddings.create(input=batch, model=model)\n",
    "        batch_embeddings = [e.embedding for e in response.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "    with open(cache_path, \"wb\") as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "\n",
    "    return embeddings\n",
    "def select_diverse_relevant_exemplars(explanations, embeddings, num_exemplars=10, seed_explanation=None):\n",
    "    kmeans = KMeans(n_clusters=num_exemplars, random_state=42).fit(embeddings)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    selected = []\n",
    "    for i in range(num_exemplars):\n",
    "        cluster_indices = np.where(cluster_labels == i)[0]\n",
    "        cluster_embeds = [embeddings[j] for j in cluster_indices]\n",
    "\n",
    "        if seed_explanation:\n",
    "            seed_embed = embeddings[explanations.index(seed_explanation)]\n",
    "            sims = cosine_similarity([seed_embed], cluster_embeds)[0]\n",
    "        else:\n",
    "            sims = cosine_similarity([centroids[i]], cluster_embeds)[0]\n",
    "\n",
    "        best_idx = cluster_indices[np.argmax(sims)]\n",
    "        selected.append(explanations[best_idx])\n",
    "\n",
    "    return selected\n",
    "\n",
    "\n",
    "corpus = load_corpus(\"./risk_trade_strategy_corpus.yaml\")\n",
    "explanations = [entry[\"explanation\"] for entry in corpus]\n",
    "embeddings = get_or_compute_embeddings(explanations, OPENAI_CLIENT)\n",
    "exemplars = select_diverse_relevant_exemplars(explanations, embeddings, num_exemplars=10)\n",
    "\n",
    "pprint(exemplars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_selected_features(corpus, max_features=10):\n",
    "    from collections import Counter\n",
    "    features = [f.strip() for entry in corpus for f in entry[\"features\"].split(\",\")]\n",
    "    required_groups = [\n",
    "        \"Stock_Data\", \"Options_Data\", \"Macro_Data\",\n",
    "        \"Economic_Data\", \"Fundamental_Data\", \"Technical_Analysis\"\n",
    "    ]\n",
    "    selected = []\n",
    "    used = set()\n",
    "    for group in required_groups:\n",
    "        group_feats = [f for f in features if f.startswith(group)]\n",
    "        if group_feats:\n",
    "            top_feat = Counter(group_feats).most_common(1)[0][0]\n",
    "            selected.append(top_feat)\n",
    "            used.add(top_feat)\n",
    "    remaining = [f for f, _ in Counter(features).most_common(30) if f not in used]\n",
    "    selected += remaining[:max(0, max_features - len(selected))]\n",
    "    return selected\n",
    "\n",
    "features = extract_selected_features(corpus)\n",
    "pprint(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Risk Strategies EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "WORD_COUNT = 50\n",
    "TOP_FEATURES = 50\n",
    "\n",
    "def clean_text(text, custom_stop_words=None):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    if custom_stop_words:\n",
    "        stop_words.update(custom_stop_words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text.lower())\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def clean_text_data(text_list, custom_stop_words=None):\n",
    "    return [clean_text(text, custom_stop_words=custom_stop_words) for text in text_list]\n",
    "\n",
    "\n",
    "def extract_corpus_data(corpus):\n",
    "    explanations = [entry[\"explanation\"] for entry in corpus]\n",
    "    features = [f.strip() for entry in corpus for f in entry[\"features\"].split(\",\")]\n",
    "    return explanations, features\n",
    "\n",
    "def compute_tfidf(data, max_features=TOP_FEATURES):\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    tfidf_matrix = vectorizer.fit_transform(data)\n",
    "    tfidf_scores = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    return tfidf_scores\n",
    "\n",
    "def compute_word_frequencies(text_data):\n",
    "    word_counter = Counter(\" \".join(text_data).split())\n",
    "    return pd.DataFrame(word_counter.most_common(WORD_COUNT), columns=[\"Word\", \"Count\"])\n",
    "\n",
    "def compute_ngrams(text_data, ngram_range=(2, 3), top_n=WORD_COUNT, custom_stop_words=None):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words=custom_stop_words)\n",
    "    ngram_matrix = vectorizer.fit_transform(text_data)\n",
    "    ngram_counts = pd.DataFrame(\n",
    "        ngram_matrix.toarray(), columns=vectorizer.get_feature_names_out()\n",
    "    ).sum(axis=0).sort_values(ascending=False).head(top_n)\n",
    "    return ngram_counts\n",
    "\n",
    "def save_and_plot(fig, file_prefix, title):\n",
    "    \"\"\"Save the plot and display it.\"\"\"\n",
    "    filename = f\"./images/{file_prefix}_{title.replace(' ', '_')}.png\"\n",
    "    os.makedirs(\"./images\", exist_ok=True)\n",
    "    fig.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "def generate_wordcloud(data, title, file_prefix):\n",
    "    wordcloud = WordCloud(width=800, height=400).generate(\" \".join(data))\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(title)\n",
    "    save_and_plot(fig, file_prefix, title)\n",
    "\n",
    "def plot_top_features(features, title, xlabel, ylabel, file_prefix):\n",
    "    features_df = pd.DataFrame(features, columns=[xlabel, ylabel])\n",
    "    features_df = features_df[~features_df[xlabel].str.startswith('Next_')]\n",
    "\n",
    "    # Compute top quartile threshold\n",
    "    threshold = features_df[ylabel].quantile(0.75)\n",
    "    top_quartile_df = features_df[features_df[ylabel] >= threshold]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, max(6, 0.3 * len(top_quartile_df))))  # dynamic height\n",
    "    ax.barh(top_quartile_df[xlabel], top_quartile_df[ylabel], color=\"skyblue\")\n",
    "    ax.set_xlabel(ylabel)\n",
    "    ax.set_ylabel(xlabel)\n",
    "    ax.set_title(title)\n",
    "    ax.invert_yaxis()\n",
    "    fig.tight_layout()\n",
    "    save_and_plot(fig, file_prefix, title)\n",
    "\n",
    "\n",
    "def analyze_corpus_with_ngrams(file_path, file_prefix, overused_words=None):\n",
    "    if overused_words is None:\n",
    "        overused_words = [\"stock\", \"potential\", \"suggesting\", \"suggests\", \"indicate\", \"indicates\",\n",
    "                          \"explanation\", \"market\", \"gains\", \"quick\", \"expert\", \"objective\", \"feature\",\n",
    "                          \"refined feature\", \"feature set\", \"refined set\", \"set emphasizes\", \"set\",\n",
    "                          \"metrics\", \"metrics\", \"assess\", \"future prompt\", \"short\", \"long\"]\n",
    "    corpus = load_corpus(file_path)\n",
    "    explanations, features = extract_corpus_data(corpus)\n",
    "    clean_explanations = clean_text_data(explanations, custom_stop_words=overused_words)\n",
    "    tfidf_scores = compute_tfidf(clean_explanations)\n",
    "    feature_counts = Counter(features)\n",
    "    explanation_bigrams = compute_ngrams(clean_explanations, ngram_range=(2, 2), custom_stop_words=overused_words)\n",
    "    explanation_trigrams = compute_ngrams(clean_explanations, ngram_range=(3, 3), custom_stop_words=overused_words)\n",
    "    generate_wordcloud(clean_explanations, \"Explanation WordCloud\", file_prefix)\n",
    "    plot_top_features(feature_counts.most_common(WORD_COUNT), \"Top Features\", \"Feature\", \"Count\", file_prefix)\n",
    "    plot_top_features(tfidf_scores.mean(axis=0).sort_values(ascending=False).head(WORD_COUNT).items(),\n",
    "                      \"Top Words in Explanations (TF-IDF)\", \"Word\", \"TF-IDF Score\", file_prefix)\n",
    "\n",
    "    for ngrams, title, color in [\n",
    "        (explanation_bigrams, \"Top Bigrams in Explanations\", \"purple\"),\n",
    "        (explanation_trigrams, \"Top Trigrams in Explanations\", \"orange\"),\n",
    "    ]:\n",
    "        # Convert to DataFrame\n",
    "        ngram_df = pd.DataFrame({ \"ngram\": ngrams.index, \"freq\": ngrams.values })\n",
    "\n",
    "        # Apply top quartile filter\n",
    "        threshold = ngram_df[\"freq\"].quantile(0.75)\n",
    "        top_ngram_df = ngram_df[ngram_df[\"freq\"] >= threshold]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, max(6, 0.3 * len(top_ngram_df))))\n",
    "        ax.barh(top_ngram_df[\"ngram\"], top_ngram_df[\"freq\"], color=color)\n",
    "        ax.set_xlabel(\"Frequency\")\n",
    "        ax.set_ylabel(\"N-grams\")\n",
    "        ax.set_title(title)\n",
    "        ax.invert_yaxis()\n",
    "        fig.tight_layout()\n",
    "        save_and_plot(fig, file_prefix, title)\n",
    "\n",
    "\n",
    "analyze_corpus_with_ngrams(corpus_file, \"risk_version1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Risk Strategies EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the above was done for high-risk, now we do the same for the low risk configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_df = expert_trades(stock_aug_data.copy(), high_risk=False)\n",
    "\n",
    "print(expert_df.columns)\n",
    "expert_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_start_date = pd.Timestamp(\"2019-06-01 00:00:00+02:00\")\n",
    "sample_end_date = pd.Timestamp(\"2019-07-30 00:00:00+02:00\")\n",
    "\n",
    "engineered_sample_df = stock_aug_data.loc[sample_start_date:sample_end_date]\n",
    "expert_sample_df = expert_df.loc[sample_start_date:sample_end_date]\n",
    "engineered_sample_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_decisions_df = llm_trades(\n",
    "    engineered_df=engineered_sample_df,\n",
    "    risk_profile=LOW_RISK_PROFILE,\n",
    "    objectives=LOW_OBJECTIVES,\n",
    "    persona=PERSONA,\n",
    "    client=OPENAI_CLIENT,\n",
    "    model=OPENAI_MODEL,\n",
    "    expert_df=expert_df,\n",
    ")\n",
    "print(llm_decisions_df['explanation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus_file = \"./norisk_trade_strategy_corpus.yaml\"\n",
    "if os.path.exists(corpus_file):\n",
    "    print(f\"Corpus file '{corpus_file}' found. Reloading...\")\n",
    "    with open(corpus_file, \"r\") as f:\n",
    "        corpus = yaml.safe_load(f)\n",
    "else:\n",
    "    print(\"Corpus file not found. Generating new corpus...\")\n",
    "    OPENAI_CLIENT = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    corpus = process_multiple_tickers(\n",
    "        tickers=TICKERS,\n",
    "        risk_profile=LOW_RISK_PROFILE,\n",
    "        objectives=LOW_OBJECTIVES,\n",
    "        persona=PERSONA,\n",
    "        client=OPENAI_CLIENT,\n",
    "        model=OPENAI_MODEL,\n",
    "        high_risk=False,\n",
    "        num_samples=PROMPT_SAMPLES,\n",
    "    )\n",
    "\n",
    "    with open(corpus_file, \"w\") as f:\n",
    "        yaml.dump(corpus, f, default_flow_style=False, allow_unicode=True, indent=2)\n",
    "\n",
    "    print(\"Corpus saved successfully.\")\n",
    "\n",
    "print(\"Corpus ready for use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_corpus_with_ngrams(corpus_file, \"norisk_version1\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5722911,
     "sourceId": 9421991,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 197612253,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "quant_drl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1234.187031,
   "end_time": "2024-09-17T20:07:16.406924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-17T19:46:42.219893",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
